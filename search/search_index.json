{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PolarRoute-Server A web server to manage requests for meshes and routes generated using the PolarRoute and MeshiPhi libraries, implemented using Django , Celery and Django REST framework . It currently takes vessel meshes created using MeshiPhi or PolarRoute-pipeline and serves requests for routes, which are calculated using PolarRoute. Setup/installation PolarRouteServer can be installed from GitHub using pip . Inside a virtual environment (e.g. venv, conda, etc.) run pip install git+https://github.com/bas-amop/PolarRoute-server To install a specific version append the tag, e.g. pip install git+https://github.com/bas-amop/PolarRoute-server@v0.1.6 Alternatively, clone this repository with git and install from source with pip install -e . Quickstart using docker compose (recommended) Use docker compose for development deployment to orchestrate celery and rabbitmq alongside the django development server. Clone this repository and run docker compose up to build and start the services. Note : In development, meshes are not automatically ingested into the database. Follow these steps to add a mesh to the database. Make a local directory structure with mkdir -p data/mesh (if it has not been created by docker compose ). If you have a vessel mesh file from MeshiPhi or PolarRoute-pipeline, copy it into ./data/mesh , which is bind-mounted into the app container. Alternatively, download an example mesh using pushd data/mesh wget http://files.bas.ac.uk/twins/polarroute/example_vehicle_meshes/amsr_southern_SDA.json.gz && \\ wget http://files.bas.ac.uk/twins/polarroute/example_vehicle_meshes/amsr_central_SDA.json.gz && \\ wget http://files.bas.ac.uk/twins/polarroute/example_vehicle_meshes/amsr_northern_SDA.json.gz gunzip amsr_*_SDA.json.gz popd Run docker compose exec app /bin/bash to open a shell inside the running app container. Run django-admin insert_mesh /usr/src/app/data/mesh/<MESH FILENAME> to insert the mesh into the database manually. Test that the app is working using the request_route tool (see Documentation ). The URL of the service should be localhost:8000 . The django development server supports hot reloading and the source code is bind-mounted into the container, so changes should be reflected in the running app. Any changes to polarrouteserver.route_api.models.py will necessitate a migration to the database. To create and run migrations, run: docker compose exec app django-admin makemigrations docker compose exec app django-admin migrate Optionally, Swagger can be used to serve an API schema. This is not started by default, but can be enabled by started docker compose with the --profile swagger option, e.g. docker compose --profile swagger up -d - the swagger UI will be served at localhost:80/swagger . Using this documentation Most of these docs are primarily aimed at developers of the package ( Development ) or administrators who want to deploy a copy of the server ( Deployment ). If you are a user/web developer who would like to request routes from PolarRoute server you should check out the Requesting Routes page and the API Reference .","title":"Home"},{"location":"#polarroute-server","text":"A web server to manage requests for meshes and routes generated using the PolarRoute and MeshiPhi libraries, implemented using Django , Celery and Django REST framework . It currently takes vessel meshes created using MeshiPhi or PolarRoute-pipeline and serves requests for routes, which are calculated using PolarRoute.","title":"PolarRoute-Server"},{"location":"#setupinstallation","text":"PolarRouteServer can be installed from GitHub using pip . Inside a virtual environment (e.g. venv, conda, etc.) run pip install git+https://github.com/bas-amop/PolarRoute-server To install a specific version append the tag, e.g. pip install git+https://github.com/bas-amop/PolarRoute-server@v0.1.6 Alternatively, clone this repository with git and install from source with pip install -e .","title":"Setup/installation"},{"location":"#quickstart-using-docker-compose-recommended","text":"Use docker compose for development deployment to orchestrate celery and rabbitmq alongside the django development server. Clone this repository and run docker compose up to build and start the services. Note : In development, meshes are not automatically ingested into the database. Follow these steps to add a mesh to the database. Make a local directory structure with mkdir -p data/mesh (if it has not been created by docker compose ). If you have a vessel mesh file from MeshiPhi or PolarRoute-pipeline, copy it into ./data/mesh , which is bind-mounted into the app container. Alternatively, download an example mesh using pushd data/mesh wget http://files.bas.ac.uk/twins/polarroute/example_vehicle_meshes/amsr_southern_SDA.json.gz && \\ wget http://files.bas.ac.uk/twins/polarroute/example_vehicle_meshes/amsr_central_SDA.json.gz && \\ wget http://files.bas.ac.uk/twins/polarroute/example_vehicle_meshes/amsr_northern_SDA.json.gz gunzip amsr_*_SDA.json.gz popd Run docker compose exec app /bin/bash to open a shell inside the running app container. Run django-admin insert_mesh /usr/src/app/data/mesh/<MESH FILENAME> to insert the mesh into the database manually. Test that the app is working using the request_route tool (see Documentation ). The URL of the service should be localhost:8000 . The django development server supports hot reloading and the source code is bind-mounted into the container, so changes should be reflected in the running app. Any changes to polarrouteserver.route_api.models.py will necessitate a migration to the database. To create and run migrations, run: docker compose exec app django-admin makemigrations docker compose exec app django-admin migrate Optionally, Swagger can be used to serve an API schema. This is not started by default, but can be enabled by started docker compose with the --profile swagger option, e.g. docker compose --profile swagger up -d - the swagger UI will be served at localhost:80/swagger .","title":"Quickstart using docker compose (recommended)"},{"location":"#using-this-documentation","text":"Most of these docs are primarily aimed at developers of the package ( Development ) or administrators who want to deploy a copy of the server ( Deployment ). If you are a user/web developer who would like to request routes from PolarRoute server you should check out the Requesting Routes page and the API Reference .","title":"Using this documentation"},{"location":"api/","text":"Note : This schema can also be viewed from an instance of PolarRoute-server at /api/schema/swagger-ui and the yaml representation from /api/schema . SwaggerUIBundle({ url: 'apischema.yml', dom_id: '#swagger-ui-1', })","title":"API Reference"},{"location":"changelog/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [Unreleased] Changed Altered the /api/recent_routes endpoint to return routes from the last 24 hours. Previously it returned routes from the current calendar day. 0.2.6 - 2025-12-17 Fixed Added missing migration. 0.2.5 - 2025-12-15 Added added ensure_adminuser command to add subtly more sophisticated behaviour to Django's createsuperuser - i.e. don't raise non-zero exit code if superuser already exists, add more useful output. Empty arrays to empty responses for a consistent response structure. Adding a \"tags\" field to the Route model. As an optional parameter, tags can be assigned to routes using a POST api/route request. This is implemented using django-taggit . Added environment variables for controlling logging behaviour: POLARROUTE_LOG_FILE_NAME, CELERY_LOG_DIR, CELERY_LOG_FILE_NAME (in addition to existing: POLARROUTE_LOG_DIR). Added rotating logging handler. Improved Improved speed of route changelist admin page. Write logs with group-write permissions. Use uv in the docker image. Changed Inappropriate use of 204 code: RecentRoutesView changed from 204 to 200 OK with an empty array and the original message (\"No recent routes found for today.\"). Inappropriate use of 204 code: VehicleTypeListView changed from 204 to 200 OK with and empty array and the original message. MeshView - Changed from 204 to 404 Not Found when mesh doesn't exist. Updated tests to reflect corrected HTTP status codes. Remove one layer of error response nesting in failed job response. Made route admin panel more read-only and faster; hide full view of JSON fields. Fixed Corrected mesh data source checking and improved warning message to reduce confusion for missing current data. Add erroneously missing rest_framework into INSTALLED_APPS . Remove unique constraint and add id field to locations fixture to prevent duplication. Corrected mesh metadata filename pattern. Corrected mesh id type in api schema. Catch more errors in route evaluation, return a better error message from evaluate route endpoint. 0.2.4 - 2025-11-11 Fixed Included migration for changes to location model. Inclusion of fixtures in source code distribution by using MANIFEST.in in place of package_data in pyproject.toml . 0.2.3 - 2025-11-10 Added This changelog! Changed Restricted upper limit of Django support to version 5.2 Name of maintainer from David Wilby to David Wyld. Moved the docker volume for the db service to a managed volume instead of a bind-mount. request_route utility move to its own module. Fixed request_route utility now does not wait for the delay period before the first status request, only after receipt of a 'PENDING' job status. Removed Support for python 3.9 Support for Django < 5.2 0.2.2 - 2025-10-14 Added Optimisation metrics exposure (time, fuel, distance) in route responses. Job ID inclusion in recent_routes response for better tracking. Recent routes output validation tests. Changed Breaking : Route response structure now consistent regardless of optimisation types available. Improved recent_routes endpoint performance by removing repeated job status calls and heavy JSON processing. Route calculated timestamp only applied when both route optimisations are complete. Re-coupled recent_routes status to Celery state using database instead of broker for better reliability/performance. Removed top-level metadata duplication in route responses. Fixed Performance issues with recent_routes endpoint loading unnecessary data. 0.2.1 - 2025-09-18 Added Response refactor for improved error code consistency. New responses.py module for centralized response handling. Response validation tests ( test_responses.py ). Location management functionality. Job status schema with all possible Celery states. Vehicle management with CRUD operations. Vehicle configuration validation using PolarRoute validator. Location fixtures for standard locations (Bird Island, Falklands, Halley, Rothera, etc.). Swagger UI served alongside the application. Changed Breaking : Separated job and route endpoints - routes now accessed via job workflow. Breaking : Route cancellation moved from route endpoint to job endpoint. Unified error responses across all endpoints for consistency. Route model now cascades deletion when job is deleted. Vehicle model expanded with additional SDA properties ( beam , hull_type , force_limit ). LocationView refactored to LocationViewSet . Fixed Route schema missing from API documentation after merge conflicts. Inconsistent error response formats across endpoints. Route cancellation bug where deletion didn't work properly. Removed Redundant \"no mesh available\" response variations - now unified. Separate route cancellation endpoint (moved to job endpoint). 0.2.0 - 2025-02-19 0.1.6 - 2024-12-09 0.1.5 - 2024-12-05 0.1.4 - 2024-11-28 0.1.3 - 2024-11-26 0.1.2 - 2024-11-25 0.1.1 - 2024-11-20 0.1.0 - 2024-11-20","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#unreleased","text":"","title":"[Unreleased]"},{"location":"changelog/#changed","text":"Altered the /api/recent_routes endpoint to return routes from the last 24 hours. Previously it returned routes from the current calendar day.","title":"Changed"},{"location":"changelog/#026-2025-12-17","text":"","title":"0.2.6 - 2025-12-17"},{"location":"changelog/#fixed","text":"Added missing migration.","title":"Fixed"},{"location":"changelog/#025-2025-12-15","text":"","title":"0.2.5 - 2025-12-15"},{"location":"changelog/#added","text":"added ensure_adminuser command to add subtly more sophisticated behaviour to Django's createsuperuser - i.e. don't raise non-zero exit code if superuser already exists, add more useful output. Empty arrays to empty responses for a consistent response structure. Adding a \"tags\" field to the Route model. As an optional parameter, tags can be assigned to routes using a POST api/route request. This is implemented using django-taggit . Added environment variables for controlling logging behaviour: POLARROUTE_LOG_FILE_NAME, CELERY_LOG_DIR, CELERY_LOG_FILE_NAME (in addition to existing: POLARROUTE_LOG_DIR). Added rotating logging handler.","title":"Added"},{"location":"changelog/#improved","text":"Improved speed of route changelist admin page. Write logs with group-write permissions. Use uv in the docker image.","title":"Improved"},{"location":"changelog/#changed_1","text":"Inappropriate use of 204 code: RecentRoutesView changed from 204 to 200 OK with an empty array and the original message (\"No recent routes found for today.\"). Inappropriate use of 204 code: VehicleTypeListView changed from 204 to 200 OK with and empty array and the original message. MeshView - Changed from 204 to 404 Not Found when mesh doesn't exist. Updated tests to reflect corrected HTTP status codes. Remove one layer of error response nesting in failed job response. Made route admin panel more read-only and faster; hide full view of JSON fields.","title":"Changed"},{"location":"changelog/#fixed_1","text":"Corrected mesh data source checking and improved warning message to reduce confusion for missing current data. Add erroneously missing rest_framework into INSTALLED_APPS . Remove unique constraint and add id field to locations fixture to prevent duplication. Corrected mesh metadata filename pattern. Corrected mesh id type in api schema. Catch more errors in route evaluation, return a better error message from evaluate route endpoint.","title":"Fixed"},{"location":"changelog/#024-2025-11-11","text":"","title":"0.2.4 - 2025-11-11"},{"location":"changelog/#fixed_2","text":"Included migration for changes to location model. Inclusion of fixtures in source code distribution by using MANIFEST.in in place of package_data in pyproject.toml .","title":"Fixed"},{"location":"changelog/#023-2025-11-10","text":"","title":"0.2.3 - 2025-11-10"},{"location":"changelog/#added_1","text":"This changelog!","title":"Added"},{"location":"changelog/#changed_2","text":"Restricted upper limit of Django support to version 5.2 Name of maintainer from David Wilby to David Wyld. Moved the docker volume for the db service to a managed volume instead of a bind-mount.","title":"Changed"},{"location":"changelog/#request_route","text":"utility move to its own module.","title":"request_route"},{"location":"changelog/#fixed_3","text":"request_route utility now does not wait for the delay period before the first status request, only after receipt of a 'PENDING' job status.","title":"Fixed"},{"location":"changelog/#removed","text":"Support for python 3.9 Support for Django < 5.2","title":"Removed"},{"location":"changelog/#022-2025-10-14","text":"","title":"0.2.2 - 2025-10-14"},{"location":"changelog/#added_2","text":"Optimisation metrics exposure (time, fuel, distance) in route responses. Job ID inclusion in recent_routes response for better tracking. Recent routes output validation tests.","title":"Added"},{"location":"changelog/#changed_3","text":"Breaking : Route response structure now consistent regardless of optimisation types available. Improved recent_routes endpoint performance by removing repeated job status calls and heavy JSON processing. Route calculated timestamp only applied when both route optimisations are complete. Re-coupled recent_routes status to Celery state using database instead of broker for better reliability/performance. Removed top-level metadata duplication in route responses.","title":"Changed"},{"location":"changelog/#fixed_4","text":"Performance issues with recent_routes endpoint loading unnecessary data.","title":"Fixed"},{"location":"changelog/#021-2025-09-18","text":"","title":"0.2.1 - 2025-09-18"},{"location":"changelog/#added_3","text":"Response refactor for improved error code consistency. New responses.py module for centralized response handling. Response validation tests ( test_responses.py ). Location management functionality. Job status schema with all possible Celery states. Vehicle management with CRUD operations. Vehicle configuration validation using PolarRoute validator. Location fixtures for standard locations (Bird Island, Falklands, Halley, Rothera, etc.). Swagger UI served alongside the application.","title":"Added"},{"location":"changelog/#changed_4","text":"Breaking : Separated job and route endpoints - routes now accessed via job workflow. Breaking : Route cancellation moved from route endpoint to job endpoint. Unified error responses across all endpoints for consistency. Route model now cascades deletion when job is deleted. Vehicle model expanded with additional SDA properties ( beam , hull_type , force_limit ). LocationView refactored to LocationViewSet .","title":"Changed"},{"location":"changelog/#fixed_5","text":"Route schema missing from API documentation after merge conflicts. Inconsistent error response formats across endpoints. Route cancellation bug where deletion didn't work properly.","title":"Fixed"},{"location":"changelog/#removed_1","text":"Redundant \"no mesh available\" response variations - now unified. Separate route cancellation endpoint (moved to job endpoint).","title":"Removed"},{"location":"changelog/#020-2025-02-19","text":"","title":"0.2.0 - 2025-02-19"},{"location":"changelog/#016-2024-12-09","text":"","title":"0.1.6 - 2024-12-09"},{"location":"changelog/#015-2024-12-05","text":"","title":"0.1.5 - 2024-12-05"},{"location":"changelog/#014-2024-11-28","text":"","title":"0.1.4 - 2024-11-28"},{"location":"changelog/#013-2024-11-26","text":"","title":"0.1.3 - 2024-11-26"},{"location":"changelog/#012-2024-11-25","text":"","title":"0.1.2 - 2024-11-25"},{"location":"changelog/#011-2024-11-20","text":"","title":"0.1.1 - 2024-11-20"},{"location":"changelog/#010-2024-11-20","text":"","title":"0.1.0 - 2024-11-20"},{"location":"configuration/","text":"Configuration Configuration of PolarRouteServer works with environment variables. You can either set these directly or from a .env file. An example .env file is included in the repo as env.example . Environment variables used directly by the Django site are prefixed wit POLARROUTE_ and those which configure Celery are prefixed with CELERY_ . Mesh settings POLARROUTE_MESH_DIR - absolute path to directory where mesh files will be made available (this location is periodically checked in production and new files ingested into the database based on the metadata file). A warning is logged in production if this is not set. POLARROUTE_MESH_METADATA_DIR - as above, absolute path to directory where mesh metadata files will be made available. If this is not set, the value of POLARROUTE_MESH_DIR is used and a warning to this effect is logged. Django settings The following are inherited from Django and more information can be found on their effects via the Django docs . POLARROUTE_DEBUG - enables Django debug options, must be False in production (default: False ) POLARROUTE_SECRET_KEY - secret hash used for cookie signing etc. Must be set in production. A random key is generated if one is not set. DJANGO_SETTINGS_MODULE - sets the settings envrionment. Options: polarrouteserver.settings.{production,development,test} (Default: polarrroutesserver.settings.production ) POLARROUTE_ALLOWED_HOSTS - comma-separated (no spaces) list of IP addresses or hostnames allowed for the server. POLARROUTE_CORS_ALLOWED_ORIGINS - comma-separated (no spaces) list of IP addresses allowed for Cross Origin Site Requests. (See django-cors-headers on PyPI for more.) CELERY_BROKER_URL - URL for rabbitMQ message broker used by celery. (Default: amqp://guest:guest@localhost ) POLARROUTE_LOG_LEVEL - sets the logging level from standard log level options: INFO, DEBUG, ERROR, WARNING etc. (Default: INFO ) POLARROUTE_LOG_DIR - sets the output directory for logs. By default only used in production settings environment. POLARROUTE_STATIC_ROOT - the path to directory used for static file serving in production, e.g. \"/var/www/example.com/static/\" (Default: None ) Note this is only used for the admin panel in this application. Database settings POLARROUTE_DB_NAME - postgres database name (default: polarroute ) POLARROUTE_DB_USER - postgres database user (default: polarroute ) POLARROUTE_DB_PASSWORD - postgres database password (default: polarroute ) POLARROUTE_DB_HOST - postgres database host (default: 127.0.0.1 ) POLARROUTE_DB_PORT - postgres database port (default: 5432 )","title":"Configuration"},{"location":"configuration/#configuration","text":"Configuration of PolarRouteServer works with environment variables. You can either set these directly or from a .env file. An example .env file is included in the repo as env.example . Environment variables used directly by the Django site are prefixed wit POLARROUTE_ and those which configure Celery are prefixed with CELERY_ .","title":"Configuration"},{"location":"configuration/#mesh-settings","text":"POLARROUTE_MESH_DIR - absolute path to directory where mesh files will be made available (this location is periodically checked in production and new files ingested into the database based on the metadata file). A warning is logged in production if this is not set. POLARROUTE_MESH_METADATA_DIR - as above, absolute path to directory where mesh metadata files will be made available. If this is not set, the value of POLARROUTE_MESH_DIR is used and a warning to this effect is logged.","title":"Mesh settings"},{"location":"configuration/#django-settings","text":"The following are inherited from Django and more information can be found on their effects via the Django docs . POLARROUTE_DEBUG - enables Django debug options, must be False in production (default: False ) POLARROUTE_SECRET_KEY - secret hash used for cookie signing etc. Must be set in production. A random key is generated if one is not set. DJANGO_SETTINGS_MODULE - sets the settings envrionment. Options: polarrouteserver.settings.{production,development,test} (Default: polarrroutesserver.settings.production ) POLARROUTE_ALLOWED_HOSTS - comma-separated (no spaces) list of IP addresses or hostnames allowed for the server. POLARROUTE_CORS_ALLOWED_ORIGINS - comma-separated (no spaces) list of IP addresses allowed for Cross Origin Site Requests. (See django-cors-headers on PyPI for more.) CELERY_BROKER_URL - URL for rabbitMQ message broker used by celery. (Default: amqp://guest:guest@localhost ) POLARROUTE_LOG_LEVEL - sets the logging level from standard log level options: INFO, DEBUG, ERROR, WARNING etc. (Default: INFO ) POLARROUTE_LOG_DIR - sets the output directory for logs. By default only used in production settings environment. POLARROUTE_STATIC_ROOT - the path to directory used for static file serving in production, e.g. \"/var/www/example.com/static/\" (Default: None ) Note this is only used for the admin panel in this application.","title":"Django settings"},{"location":"configuration/#database-settings","text":"POLARROUTE_DB_NAME - postgres database name (default: polarroute ) POLARROUTE_DB_USER - postgres database user (default: polarroute ) POLARROUTE_DB_PASSWORD - postgres database password (default: polarroute ) POLARROUTE_DB_HOST - postgres database host (default: 127.0.0.1 ) POLARROUTE_DB_PORT - postgres database port (default: 5432 )","title":"Database settings"},{"location":"deployment/","text":"Deployment For a production deployment, the following are required: WSGI server, e.g. Gunicorn, mod_wsgi (httpd), PostgreSQL database Celery and celery beat servers running, Access to a RabbitMQ server, Configuration Configuration of PolarRouteServer works with environment variables, these are covered in Configuration in detail. It is up to you how you choose to set these environment variables in your deployment. Setting up the database Assuming you have a running PostgreSQL database and that the environment variables are set, particularly all of the database connection settings and DJANGO_SETTINGS_MODULE run: $ django-admin migrate to build the database. When running this for the first time, you may need to point to your DJANGO_SETTINGS_MODULE : export DJANGO_SETTINGS_MODULE=polarrouteserver.settings.development Create a superuser in the database Run the following and follow the prompts. $ django-admin createsuperuser Management of a deployment All of the commands used for administration of a Django project are available post-installation via the django-admin command. Note that the envrionment variables used will need to be set in the session which you're running these commands. Note that the same commands can be run by running python manage.py where manage.py is the file contained in the top level of the repository. Of particular interest in production are: $ django-admin makemigrations # create new migrations files based on changes to models $ django-admin migrate # apply new migrations files to alter the database $ django-admin dbshell # open the database's command line interface To see more commands, run django-admin --help . In addition a custom command is available to manually insert new meshes into the database from file: $ django-admin insert_mesh <Mesh file or list of files> insert_mesh takes a filename or list of filepaths containing meshes either as .vessel.json format or gzipped vessel mesh files. Only meshes which are not present in the database will be inserted. Uniqueness is based on the md5 hash of the unzipped vessel mesh file. Configuring a web server PolarRoute-server can be served similarly to any other Django application, see Django docs for more information . Or see the instructions for httpd/mod_wsgi below. Configuring mod_wsgi If you are using mod_wsgi to serve PolarRoute-server under httpd, a typical .conf file may look something like: <VirtualHost *:443> ServerName polarroute.myserver.com DocumentRoot /path/to/my/polarrouteserver/ LogLevel info SSLEngine on SSLCertificateFile /local/certs/myserver.com.pem PassEnv DJANGO_SETTINGS_MODULE PassEnv POLARROUTE_MESH_DIR PassEnv POLARROUTE_MESH_METADATA_DIR PassEnv POLARROUTE_ALLOWED_HOSTS PassEnv POLARROUTE_CORS_ALLOWED_ORIGINS PassEnv POLARROUTE_STATIC_ROOT PassEnv CELERY_BROKER_URL PassEnv CELERYD_CHDIR PassEnv POLARROUTE_DEBUG PassEnv POLARROUTE_LOG_DIR PassEnv POLARROUTE_BASE_DIR PassEnv POLARROUTE_LOG_LEVEL PassEnv POLARROUTE_DB_NAME PassEnv POLARROUTE_DB_USER PassEnv POLARROUTE_DB_PASSWORD PassEnv POLARROUTE_DB_HOST WSGIDaemonProcess polarroute.myserver.com user=wsgi group=wsgi threads=5 python-home=/path/to/my/python/home python-path=/path/to/my/python/path WSGIProcessGroup polarroute.myserver.com WSGIApplicationGroup %{GLOBAL} WSGIScriptAlias / /path/to/my/polarrouteserver//wsgi.py Alias /static /var/www/polarroute.myserver.com/static CustomLog /var/log/httpd/access_log.polarroute.myserver.com combined ErrorLog /var/log/httpd/error_log.polarroute.myserver.com <Location /> Require all granted </Location> </VirtualHost> <Directory \"/path/to/my/polarrouteserver/\"> AllowOverride All Options -Indexes Require all granted WSGIScriptReloading On WSGIProcessGroup polarroute.myserver.com WSGIApplicationGroup %{GLOBAL} </Directory> <Directory /var/www/polarroute.myserver.com/static/> Order allow,deny Allow from all </Directory> Collecting static files PolarRoute-server itself has no static files since it is a headless server, however it does make use of Django's /admin endpoint as a database management dashboard. For this to work, we need to create a static file location, e.g. /var/www/polarroute.{{ hostname }}/static and run the following commands (noting to use the correct path to your static file location): export DJANGO_SETTINGS_MODULE=polarrouteserver.settings.production export POLARROUTE_STATIC_ROOT=/var/www/polarroute.myserver.com/static/ django-admin collecstatic This only needs to be run once. Other recommendations It is also recommended to do the following in a deployment: Add polarrouteserver and celery logs to logrotate - logfiles are written from polarrouteserver and celery to files in POLARROUTE_LOG_DIR , it is prudent to add these to a log rotation utility such as logrotate. Manage Celery, Celerybeat and rabbitmq under systemd.","title":"Deployment"},{"location":"deployment/#deployment","text":"For a production deployment, the following are required: WSGI server, e.g. Gunicorn, mod_wsgi (httpd), PostgreSQL database Celery and celery beat servers running, Access to a RabbitMQ server,","title":"Deployment"},{"location":"deployment/#configuration","text":"Configuration of PolarRouteServer works with environment variables, these are covered in Configuration in detail. It is up to you how you choose to set these environment variables in your deployment.","title":"Configuration"},{"location":"deployment/#setting-up-the-database","text":"Assuming you have a running PostgreSQL database and that the environment variables are set, particularly all of the database connection settings and DJANGO_SETTINGS_MODULE run: $ django-admin migrate to build the database. When running this for the first time, you may need to point to your DJANGO_SETTINGS_MODULE : export DJANGO_SETTINGS_MODULE=polarrouteserver.settings.development","title":"Setting up the database"},{"location":"deployment/#create-a-superuser-in-the-database","text":"Run the following and follow the prompts. $ django-admin createsuperuser","title":"Create a superuser in the database"},{"location":"deployment/#management-of-a-deployment","text":"All of the commands used for administration of a Django project are available post-installation via the django-admin command. Note that the envrionment variables used will need to be set in the session which you're running these commands. Note that the same commands can be run by running python manage.py where manage.py is the file contained in the top level of the repository. Of particular interest in production are: $ django-admin makemigrations # create new migrations files based on changes to models $ django-admin migrate # apply new migrations files to alter the database $ django-admin dbshell # open the database's command line interface To see more commands, run django-admin --help . In addition a custom command is available to manually insert new meshes into the database from file: $ django-admin insert_mesh <Mesh file or list of files> insert_mesh takes a filename or list of filepaths containing meshes either as .vessel.json format or gzipped vessel mesh files. Only meshes which are not present in the database will be inserted. Uniqueness is based on the md5 hash of the unzipped vessel mesh file.","title":"Management of a deployment"},{"location":"deployment/#configuring-a-web-server","text":"PolarRoute-server can be served similarly to any other Django application, see Django docs for more information . Or see the instructions for httpd/mod_wsgi below.","title":"Configuring a web server"},{"location":"deployment/#configuring-mod_wsgi","text":"If you are using mod_wsgi to serve PolarRoute-server under httpd, a typical .conf file may look something like: <VirtualHost *:443> ServerName polarroute.myserver.com DocumentRoot /path/to/my/polarrouteserver/ LogLevel info SSLEngine on SSLCertificateFile /local/certs/myserver.com.pem PassEnv DJANGO_SETTINGS_MODULE PassEnv POLARROUTE_MESH_DIR PassEnv POLARROUTE_MESH_METADATA_DIR PassEnv POLARROUTE_ALLOWED_HOSTS PassEnv POLARROUTE_CORS_ALLOWED_ORIGINS PassEnv POLARROUTE_STATIC_ROOT PassEnv CELERY_BROKER_URL PassEnv CELERYD_CHDIR PassEnv POLARROUTE_DEBUG PassEnv POLARROUTE_LOG_DIR PassEnv POLARROUTE_BASE_DIR PassEnv POLARROUTE_LOG_LEVEL PassEnv POLARROUTE_DB_NAME PassEnv POLARROUTE_DB_USER PassEnv POLARROUTE_DB_PASSWORD PassEnv POLARROUTE_DB_HOST WSGIDaemonProcess polarroute.myserver.com user=wsgi group=wsgi threads=5 python-home=/path/to/my/python/home python-path=/path/to/my/python/path WSGIProcessGroup polarroute.myserver.com WSGIApplicationGroup %{GLOBAL} WSGIScriptAlias / /path/to/my/polarrouteserver//wsgi.py Alias /static /var/www/polarroute.myserver.com/static CustomLog /var/log/httpd/access_log.polarroute.myserver.com combined ErrorLog /var/log/httpd/error_log.polarroute.myserver.com <Location /> Require all granted </Location> </VirtualHost> <Directory \"/path/to/my/polarrouteserver/\"> AllowOverride All Options -Indexes Require all granted WSGIScriptReloading On WSGIProcessGroup polarroute.myserver.com WSGIApplicationGroup %{GLOBAL} </Directory> <Directory /var/www/polarroute.myserver.com/static/> Order allow,deny Allow from all </Directory>","title":"Configuring mod_wsgi"},{"location":"deployment/#collecting-static-files","text":"PolarRoute-server itself has no static files since it is a headless server, however it does make use of Django's /admin endpoint as a database management dashboard. For this to work, we need to create a static file location, e.g. /var/www/polarroute.{{ hostname }}/static and run the following commands (noting to use the correct path to your static file location): export DJANGO_SETTINGS_MODULE=polarrouteserver.settings.production export POLARROUTE_STATIC_ROOT=/var/www/polarroute.myserver.com/static/ django-admin collecstatic This only needs to be run once.","title":"Collecting static files"},{"location":"deployment/#other-recommendations","text":"It is also recommended to do the following in a deployment: Add polarrouteserver and celery logs to logrotate - logfiles are written from polarrouteserver and celery to files in POLARROUTE_LOG_DIR , it is prudent to add these to a log rotation utility such as logrotate. Manage Celery, Celerybeat and rabbitmq under systemd.","title":"Other recommendations"},{"location":"development/","text":"Development Depends on: Python >=3.11 docker for running rabbitmq Make Clone the repository and create and activate a python virtual environment of your choice. Inside a virtual environment or machine: pip install -e .[dev] Make sure you have a running instance of the database, by running docker compose up , if it is not running already. Before first use, create the database by running make migrate To start all of the services needed for the dev deployment run: make serve-dev (which sets the DJANGO_SETTINGS_MODULE environment variable and spins up celery, rabbitmq in a docker container, and the Django development server) For development, also install and use the development tools with pre-commit install The pre-commit hooks include automatic API schema generation. When you commit changes to polarrouteserver/route_api/views.py , the API schema ( docs/apischema.yml ) will be automatically updated and included in your commit. A number of helpful development tools are made available through the Makefile , to see a description of each of these commands, run make (with no arguments) from the top-level of this directory. Important : Please ensure all changes are included in CHANGELOG.md in a human-friendly format. Release/Versioning Version numbers should be used in tagging commits on the main branch and reflected in the pyproject.toml file and should be of the form v0.1.7 using the semantic versioning convention. Note on version numbers : Setuptools-scm requires version numbers that begin with a v and setuptools requires PEP 440-compliant version numbers , e.g. v0.1.7 , or for non release versions: v0.1.7a1 for alphas, v0.1.7rc1 for release candidates. Installing the package will fail if tags have version numbers deviating from this format. Release preparation (i.e. updating version numbers in CHANGELOG.md and apischema.yml ) can be done automatically with make prep-release version=<VERSION-NUMBER> (without the 'v'). Note that this does not rebuild the API schema, just changes the version number. Building & deploying the documentation The documentation should build automatically on pushes to main using GitHub actions, if you want to build and deploy the docs manually, follow these steps: Run make build-docs to build the docs to the ./site directory. Then run make deploy-docs to deploy to the gh-pages branch of the repository. You must have write access to the repo. Making changes to the API The API is documented in ./docs/apischema.yml using the OpenAPI 3.0 standard (formerly known as swagger). If you have pre-commit hooks installed ( pre-commit install ), the API schema will be automatically updated when you commit changes to Python files. The updated schema will be included in your commit. You can also manually re-generate the schema by running: make build-apischema # or directly: python manage.py spectacular --color --validate --file docs/apischema.yml Aim to resolve any warnings/errors before committing. The generated schema can be checked by building the docs and checking the API reference page or serving using swagger ( make start-swagger ). Error codes and response schemas Standard error codes and responses are defined in the ResponseMixin class in responses.py . Where possible, try to align standard responses (e.g. 200 SUCCESS, 202 ACCEPTED, 400 BAD REQUESTS, 404 NOT FOUND) to these standard codes and responses. Views in views.py can inherit ResponseMixin class to make use of these standard responses. Docker containers and compose configuration PolarRoute-server relies on four different services, orchestrated by docker compose , to each be running in their own docker container. As a user, you run a single docker compose up command to build and start these services. As a developer, it is useful to be aware of what exactly these containers are doing. Pre-fixed by polarroute-server- , the four services/containers are: * db-* : a PostgreSQL database. * rabbitmq-* : RabbitMQ. * celery-* : Celery. * app-* : The Django server running PolarRoute-server's route API. Certain actions may rely on just a single service to be running, for example make migrate requires polarroute-server-db-1 to be running. However, in practice, you will always be running all four containers at the same time. Configurations for docker compose up 's execution are set in compose.yml .","title":"Development"},{"location":"development/#development","text":"Depends on: Python >=3.11 docker for running rabbitmq Make Clone the repository and create and activate a python virtual environment of your choice. Inside a virtual environment or machine: pip install -e .[dev] Make sure you have a running instance of the database, by running docker compose up , if it is not running already. Before first use, create the database by running make migrate To start all of the services needed for the dev deployment run: make serve-dev (which sets the DJANGO_SETTINGS_MODULE environment variable and spins up celery, rabbitmq in a docker container, and the Django development server) For development, also install and use the development tools with pre-commit install The pre-commit hooks include automatic API schema generation. When you commit changes to polarrouteserver/route_api/views.py , the API schema ( docs/apischema.yml ) will be automatically updated and included in your commit. A number of helpful development tools are made available through the Makefile , to see a description of each of these commands, run make (with no arguments) from the top-level of this directory. Important : Please ensure all changes are included in CHANGELOG.md in a human-friendly format.","title":"Development"},{"location":"development/#releaseversioning","text":"Version numbers should be used in tagging commits on the main branch and reflected in the pyproject.toml file and should be of the form v0.1.7 using the semantic versioning convention. Note on version numbers : Setuptools-scm requires version numbers that begin with a v and setuptools requires PEP 440-compliant version numbers , e.g. v0.1.7 , or for non release versions: v0.1.7a1 for alphas, v0.1.7rc1 for release candidates. Installing the package will fail if tags have version numbers deviating from this format. Release preparation (i.e. updating version numbers in CHANGELOG.md and apischema.yml ) can be done automatically with make prep-release version=<VERSION-NUMBER> (without the 'v'). Note that this does not rebuild the API schema, just changes the version number.","title":"Release/Versioning"},{"location":"development/#building-deploying-the-documentation","text":"The documentation should build automatically on pushes to main using GitHub actions, if you want to build and deploy the docs manually, follow these steps: Run make build-docs to build the docs to the ./site directory. Then run make deploy-docs to deploy to the gh-pages branch of the repository. You must have write access to the repo.","title":"Building &amp; deploying the documentation"},{"location":"development/#making-changes-to-the-api","text":"The API is documented in ./docs/apischema.yml using the OpenAPI 3.0 standard (formerly known as swagger). If you have pre-commit hooks installed ( pre-commit install ), the API schema will be automatically updated when you commit changes to Python files. The updated schema will be included in your commit. You can also manually re-generate the schema by running: make build-apischema # or directly: python manage.py spectacular --color --validate --file docs/apischema.yml Aim to resolve any warnings/errors before committing. The generated schema can be checked by building the docs and checking the API reference page or serving using swagger ( make start-swagger ).","title":"Making changes to the API"},{"location":"development/#error-codes-and-response-schemas","text":"Standard error codes and responses are defined in the ResponseMixin class in responses.py . Where possible, try to align standard responses (e.g. 200 SUCCESS, 202 ACCEPTED, 400 BAD REQUESTS, 404 NOT FOUND) to these standard codes and responses. Views in views.py can inherit ResponseMixin class to make use of these standard responses.","title":"Error codes and response schemas"},{"location":"development/#docker-containers-and-compose-configuration","text":"PolarRoute-server relies on four different services, orchestrated by docker compose , to each be running in their own docker container. As a user, you run a single docker compose up command to build and start these services. As a developer, it is useful to be aware of what exactly these containers are doing. Pre-fixed by polarroute-server- , the four services/containers are: * db-* : a PostgreSQL database. * rabbitmq-* : RabbitMQ. * celery-* : Celery. * app-* : The Django server running PolarRoute-server's route API. Certain actions may rely on just a single service to be running, for example make migrate requires polarroute-server-db-1 to be running. However, in practice, you will always be running all four containers at the same time. Configurations for docker compose up 's execution are set in compose.yml .","title":"Docker containers and compose configuration"},{"location":"how-polarroute-server-works/","text":"How PolarRoute-server works This page gives an overview of the architecture and approach of the software for developers or administrators of PolarRoute-server. PolarRoute-server architecture As with all Django apps, PolarRoute-server follows a model-view-controller-like architecture ( see Django FAQ for the specifics ) in which a models.py file defines the tables in the database; views.py defines the handling of HTTP requests. Most Django apps also have templates, but since PolarRoute-server is headless, we don't need these. The route request workflow is separated into distinct endpoints: Route Request Submission : User submits a route request via POST to the /api/route endpoint. Job Creation : A celery job is created for route calculation (defined in tasks.py ) and the client receives a job ID and status URL. Job Status Monitoring : Client polls the /api/job/{job_id} endpoint by GET request to monitor calculation progress. Route Data Retrieval : Once the job is complete, client retrieves the route data from /api/route/{route_id} endpoint. In short: POST /api/route : Submit route calculation request \u2192 returns job ID. GET /api/job/{job_id} : Monitor job status and progress. DELETE /api/job/{job_id} : Cancel running job. GET /api/route/{route_id} : Retrieve calculated route data. To calculate a route, PolarRoute requires a mesh that covers the area of the start and end points of the route. Ingesting meshes into the database For the time-being, meshes are calculated separately to PolarRoute-server, either with PolarRoute-pipeline or with MeshiPhi directly. The application takes vessel meshes, with the vessel transformation already applied. Meshes can be ingested into the database manually or automatically. By default, development deployments (using the polarrouteserver/settings/development.py settings) perform no automatic mesh ingestion, and production deployments (using the polarrouteserver/settings/production.py settings) use celery-beat to perform automatic ingestion of meshes every 10 minutes, running the import_new_meshes task ( polarrouteserver/route_api/tasks.py ). Automatically Meshes are found automatically in the directories specified using the POLARROUTE_MESH_DIR & POLARROUTE_MESH_METADATA_DIR environment variables (see Configuration for specific behaviour). Mesh metadata files produced by PolarRoute-pipeline are used to validate newly available meshes, only meshes which are not already in the database (determined using their md5 hash) are ingested. Mesh metadatafiles must be named according to the format upload_metadata_*.yaml.gz to be found. Manually Individual or lists of mesh files can be ingested into the database by running the insert_mesh command using django-admin or python manage.py , e.g. django-admin insert_mesh path/to/my/mesh.vessel.json . insert_mesh can take json files or json.gz files. Route requests and jobs When a route is requested, the select_mesh function is called to determine which mesh to use (described below in Mesh selection ) unless a specific mesh id is requested in the route request. The route_exists function is called for the start and end points and the mesh selected, if there is already an existing route which was successful, this is returned unless the client specifies force_new_route: true , in which case the route is recalculated. Whether a route is considered to \"exist\" or not depends on a tolerance in the haversine distance of the requested start and end locations compared to routes which have already been calculated. This distance by default is 1 nautical mile (set by the WAYPOINT_DISTANCE_TOLERANCE setting). In other words, if a route is requested where the requested start point is within 1NM of a route already calculated and the same is true of the end point, this route is returned under default conditions. Note that if a newer mesh is available, a new route will be calculated. Because route optimisation jobs can take several minutes, this is done by an asynchronous job queue managed by celery. If the route optimisation fails, the next mesh in priority order is tried if the failure is due to the route being \"inaccessible\" on the mesh. Mesh selection Before a route is calculated, a priority list of meshes is created by polarrouteserver.route_api.utils.select_mesh . It takes all of the meshes that contain the requested start and end coordinates and that were created on the latest date available out of those meshes and returns this list of meshes sorted from smallest to largest total area. Troubleshooting","title":"How PolarRoute-server works"},{"location":"how-polarroute-server-works/#how-polarroute-server-works","text":"This page gives an overview of the architecture and approach of the software for developers or administrators of PolarRoute-server.","title":"How PolarRoute-server works"},{"location":"how-polarroute-server-works/#polarroute-server-architecture","text":"As with all Django apps, PolarRoute-server follows a model-view-controller-like architecture ( see Django FAQ for the specifics ) in which a models.py file defines the tables in the database; views.py defines the handling of HTTP requests. Most Django apps also have templates, but since PolarRoute-server is headless, we don't need these. The route request workflow is separated into distinct endpoints: Route Request Submission : User submits a route request via POST to the /api/route endpoint. Job Creation : A celery job is created for route calculation (defined in tasks.py ) and the client receives a job ID and status URL. Job Status Monitoring : Client polls the /api/job/{job_id} endpoint by GET request to monitor calculation progress. Route Data Retrieval : Once the job is complete, client retrieves the route data from /api/route/{route_id} endpoint. In short: POST /api/route : Submit route calculation request \u2192 returns job ID. GET /api/job/{job_id} : Monitor job status and progress. DELETE /api/job/{job_id} : Cancel running job. GET /api/route/{route_id} : Retrieve calculated route data. To calculate a route, PolarRoute requires a mesh that covers the area of the start and end points of the route.","title":"PolarRoute-server architecture"},{"location":"how-polarroute-server-works/#ingesting-meshes-into-the-database","text":"For the time-being, meshes are calculated separately to PolarRoute-server, either with PolarRoute-pipeline or with MeshiPhi directly. The application takes vessel meshes, with the vessel transformation already applied. Meshes can be ingested into the database manually or automatically. By default, development deployments (using the polarrouteserver/settings/development.py settings) perform no automatic mesh ingestion, and production deployments (using the polarrouteserver/settings/production.py settings) use celery-beat to perform automatic ingestion of meshes every 10 minutes, running the import_new_meshes task ( polarrouteserver/route_api/tasks.py ).","title":"Ingesting meshes into the database"},{"location":"how-polarroute-server-works/#automatically","text":"Meshes are found automatically in the directories specified using the POLARROUTE_MESH_DIR & POLARROUTE_MESH_METADATA_DIR environment variables (see Configuration for specific behaviour). Mesh metadata files produced by PolarRoute-pipeline are used to validate newly available meshes, only meshes which are not already in the database (determined using their md5 hash) are ingested. Mesh metadatafiles must be named according to the format upload_metadata_*.yaml.gz to be found.","title":"Automatically"},{"location":"how-polarroute-server-works/#manually","text":"Individual or lists of mesh files can be ingested into the database by running the insert_mesh command using django-admin or python manage.py , e.g. django-admin insert_mesh path/to/my/mesh.vessel.json . insert_mesh can take json files or json.gz files.","title":"Manually"},{"location":"how-polarroute-server-works/#route-requests-and-jobs","text":"When a route is requested, the select_mesh function is called to determine which mesh to use (described below in Mesh selection ) unless a specific mesh id is requested in the route request. The route_exists function is called for the start and end points and the mesh selected, if there is already an existing route which was successful, this is returned unless the client specifies force_new_route: true , in which case the route is recalculated. Whether a route is considered to \"exist\" or not depends on a tolerance in the haversine distance of the requested start and end locations compared to routes which have already been calculated. This distance by default is 1 nautical mile (set by the WAYPOINT_DISTANCE_TOLERANCE setting). In other words, if a route is requested where the requested start point is within 1NM of a route already calculated and the same is true of the end point, this route is returned under default conditions. Note that if a newer mesh is available, a new route will be calculated. Because route optimisation jobs can take several minutes, this is done by an asynchronous job queue managed by celery. If the route optimisation fails, the next mesh in priority order is tried if the failure is due to the route being \"inaccessible\" on the mesh.","title":"Route requests and jobs"},{"location":"how-polarroute-server-works/#mesh-selection","text":"Before a route is calculated, a priority list of meshes is created by polarrouteserver.route_api.utils.select_mesh . It takes all of the meshes that contain the requested start and end coordinates and that were created on the latest date available out of those meshes and returns this list of meshes sorted from smallest to largest total area.","title":"Mesh selection"},{"location":"how-polarroute-server-works/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"requesting-routes/","text":"Requesting Routes Using the in-built request_route utility (simplest) A route request script is available in this repo ( ./request_route/request_route.py ) to be used as a utility for making route requests. To obtain, either: Clone this whole repo Download the file from its GitHub page here: https://github.com/bas-amop/PolarRoute-server/blob/main/request_route/route_request.py This can be done with wget by running: wget https://raw.githubusercontent.com/bas-amop/PolarRoute-server/refs/heads/main/request_route/request_route.py To run, you'll just need python ~3.11 installed. Earlier versions of python may work, but are untested. Usage Help for the utility can be printed out by running python request_route.py --help . Alternatively, if you have the package installed, a command named request_route is made available. $ request_route --help # OR $ python request_route.py --help usage: request_route.py [-h] [-u URL] -s [START] -e [END] [-d [DELAY]] [-n [REQUESTS]] [-m [MESHID]] [-f] [-o [OUTPUT]] Requests a route from polarRouteServer, monitors job status until complete, then retrieves the route data. Specify start and end points by coordinates or from one of the standard locations: ['bird', 'falklands', 'halley', 'rothera', 'kep', 'signy', 'nyalesund', 'harwich', 'rosyth'] options: -h, --help show this help message and exit -u URL, --url URL Base URL to send request to. -s [START], --start [START] Start location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 -e [END], --end [END] End location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 -d [DELAY], --delay [DELAY] (integer) number of seconds to delay between status calls. Default: 30 -n [REQUESTS], --requests [REQUESTS] (integer) number of status requests to make before stopping. Default: 10 -m [MESHID], --meshid [MESHID] (integer) Custom mesh ID. -f, --force Force polarRouteServer to recalculate the route even if it is already available. -o [OUTPUT], --output [OUTPUT] File path to write out route to. (Default: None and print to stdout) So to request a route from Falklands to Rothera, for example: python request_route.py --url http://example-polar-route-server.com -s falklands -e rothera --delay 120 --output demo_output.json This will request the route from the server running at http://example-polar-route-server.com , and initiate a route calculation if one is not already available. The utility will then monitor the job status every 120 seconds until the route calculation is complete. The HTTP response from each request will be printed to stdout. Once the route is available it will be retrieved and returned, or if the maximum number of attempts have passed, the utility will stop. By making HTTP requests For details on the API, see the API reference page . The route request workflow consists of three steps: 1. Submit Route Request Make a POST request to the /api/route endpoint to submit a route calculation job: curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{\"start_lat\":\"-51.73\",\"start_lon\":\"-57.71\", \"end_lat\":\"-54.03\",\"end_lon\":\"-38.04\"}' \\ http://localhost:8000/api/route This will return a response containing: id : The job ID for monitoring status. status-url : URL for checking job status (e.g., http://localhost:8000/api/job/{job_id} ). If a pre-existing route is found, it may be returned immediately. 2. Monitor Job Status Use the job ID to monitor the calculation status by making GET requests to the /api/job/{job_id} endpoint: curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/job/5c39308e-b88c-4988-9e4b-1c33bc97c90c The response will include: status : Current job status. Possible values (these are Celery states ): PENDING : Task is waiting for execution STARTED : Task has been started SUCCESS : Task executed successfully (route data is ready) FAILURE : Task failed with an exception RETRY : Task is being retried after failure REVOKED : Task was revoked/cancelled route_id : The route ID for data retrieval (available when status is SUCCESS). route_url : Direct URL to retrieve the route data (e.g., http://localhost:8000/api/route/{route_id} ). info : Error details (only present when status is FAILURE). 3. Retrieve Route Data Once the job status is SUCCESS, retrieve the actual route data using the route ID: curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/route/9 This will return the complete route data. Optional: Cancel Job You can cancel a running job by making a DELETE request to the job endpoint: curl --header \"Content-Type: application/json\" \\ --request DELETE \\ http://localhost:8000/api/job/5c39308e-b88c-4988-9e4b-1c33bc97c90c","title":"Requesting Routes"},{"location":"requesting-routes/#requesting-routes","text":"","title":"Requesting Routes"},{"location":"requesting-routes/#using-the-in-built-request_route-utility-simplest","text":"A route request script is available in this repo ( ./request_route/request_route.py ) to be used as a utility for making route requests. To obtain, either: Clone this whole repo Download the file from its GitHub page here: https://github.com/bas-amop/PolarRoute-server/blob/main/request_route/route_request.py This can be done with wget by running: wget https://raw.githubusercontent.com/bas-amop/PolarRoute-server/refs/heads/main/request_route/request_route.py To run, you'll just need python ~3.11 installed. Earlier versions of python may work, but are untested.","title":"Using the in-built request_route utility (simplest)"},{"location":"requesting-routes/#usage","text":"Help for the utility can be printed out by running python request_route.py --help . Alternatively, if you have the package installed, a command named request_route is made available. $ request_route --help # OR $ python request_route.py --help usage: request_route.py [-h] [-u URL] -s [START] -e [END] [-d [DELAY]] [-n [REQUESTS]] [-m [MESHID]] [-f] [-o [OUTPUT]] Requests a route from polarRouteServer, monitors job status until complete, then retrieves the route data. Specify start and end points by coordinates or from one of the standard locations: ['bird', 'falklands', 'halley', 'rothera', 'kep', 'signy', 'nyalesund', 'harwich', 'rosyth'] options: -h, --help show this help message and exit -u URL, --url URL Base URL to send request to. -s [START], --start [START] Start location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 -e [END], --end [END] End location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 -d [DELAY], --delay [DELAY] (integer) number of seconds to delay between status calls. Default: 30 -n [REQUESTS], --requests [REQUESTS] (integer) number of status requests to make before stopping. Default: 10 -m [MESHID], --meshid [MESHID] (integer) Custom mesh ID. -f, --force Force polarRouteServer to recalculate the route even if it is already available. -o [OUTPUT], --output [OUTPUT] File path to write out route to. (Default: None and print to stdout) So to request a route from Falklands to Rothera, for example: python request_route.py --url http://example-polar-route-server.com -s falklands -e rothera --delay 120 --output demo_output.json This will request the route from the server running at http://example-polar-route-server.com , and initiate a route calculation if one is not already available. The utility will then monitor the job status every 120 seconds until the route calculation is complete. The HTTP response from each request will be printed to stdout. Once the route is available it will be retrieved and returned, or if the maximum number of attempts have passed, the utility will stop.","title":"Usage"},{"location":"requesting-routes/#by-making-http-requests","text":"For details on the API, see the API reference page . The route request workflow consists of three steps:","title":"By making HTTP requests"},{"location":"requesting-routes/#1-submit-route-request","text":"Make a POST request to the /api/route endpoint to submit a route calculation job: curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{\"start_lat\":\"-51.73\",\"start_lon\":\"-57.71\", \"end_lat\":\"-54.03\",\"end_lon\":\"-38.04\"}' \\ http://localhost:8000/api/route This will return a response containing: id : The job ID for monitoring status. status-url : URL for checking job status (e.g., http://localhost:8000/api/job/{job_id} ). If a pre-existing route is found, it may be returned immediately.","title":"1. Submit Route Request"},{"location":"requesting-routes/#2-monitor-job-status","text":"Use the job ID to monitor the calculation status by making GET requests to the /api/job/{job_id} endpoint: curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/job/5c39308e-b88c-4988-9e4b-1c33bc97c90c The response will include: status : Current job status. Possible values (these are Celery states ): PENDING : Task is waiting for execution STARTED : Task has been started SUCCESS : Task executed successfully (route data is ready) FAILURE : Task failed with an exception RETRY : Task is being retried after failure REVOKED : Task was revoked/cancelled route_id : The route ID for data retrieval (available when status is SUCCESS). route_url : Direct URL to retrieve the route data (e.g., http://localhost:8000/api/route/{route_id} ). info : Error details (only present when status is FAILURE).","title":"2. Monitor Job Status"},{"location":"requesting-routes/#3-retrieve-route-data","text":"Once the job status is SUCCESS, retrieve the actual route data using the route ID: curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/route/9 This will return the complete route data.","title":"3. Retrieve Route Data"},{"location":"requesting-routes/#optional-cancel-job","text":"You can cancel a running job by making a DELETE request to the job endpoint: curl --header \"Content-Type: application/json\" \\ --request DELETE \\ http://localhost:8000/api/job/5c39308e-b88c-4988-9e4b-1c33bc97c90c","title":"Optional: Cancel Job"},{"location":"vehicle-management/","text":"Vehicle Management In order to add vehicles to environment meshes, they will first need to be created in the database. For details on the API, see the API reference page . Creating vehicles To request a vehicle to be added to the database, make a POST request to the /api/vehicle endpoint, for example with the following CURL: curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{ \"vessel_type\": \"SDA\", \"max_speed\": 26.5, \"unit\": \"km/hr\", \"beam\": 24.0, \"hull_type\": \"slender\", \"force_limit\": 96634.5, \"max_ice_conc\": 80, \"min_depth\": 10 }' \\ http://localhost:8000/api/vehicle This will create a vehicle of vessel_type \"SDA\" in the database. Note that vessel_type is unique, and any subsequent request to create the same vessel type will result in an error. Updating vehicle properties Should you wish to update a vessel_type 's properties after creation, you can do so using the force_properties argument in your request. Let's say we actually wanted to display the speed in knots: curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{ \"vessel_type\": \"SDA\", \"max_speed\": 14.3, \"unit\": \"knots\", \"beam\": 24.0, \"hull_type\": \"slender\", \"force_limit\": 96634.5, \"max_ice_conc\": 80, \"min_depth\": 10, \"force_properties\":\"true\" }' \\ http://localhost:8000/api/vehicle With \"force_properties\" set to \"true\" , the request will be accepted and the properties for \"SDA\" will be updated. Requesting a list of all available vehicles To request a list of all available vehicles in the database, you can make a GET request to the api/vehicle/available endpoint: curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/vehicle/available Requesting vehicles Requesting a specific vehicle To request a specific vehicle to be returned, you can make a GET request to the api/vehicle endpoint, adding the vessel_type to the end of the endpoint, for example api/vehicle/SDA : curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/vehicle/SDA/ Requesting all vehicles If you make a GET request to api/vehicle without specifying the vessel_type , all vehicles will be returned. curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/vehicle Deleting a vehicle To request a vehicle to be removed from the database, you can make a DELETE request to api/vehicle , specifying the vessel_type in the URL, just as with specific vehicle GET requests, api/vehicle/SDA : curl --header \"Content-Type: application/json\" \\ --request DELETE \\ http://localhost:8000/api/vehicle/SDA/ Removing all vehicles in one go is not currently supported. Adding a vehicle to an environment mesh Coming soon.","title":"Vehicle Management"},{"location":"vehicle-management/#vehicle-management","text":"In order to add vehicles to environment meshes, they will first need to be created in the database. For details on the API, see the API reference page .","title":"Vehicle Management"},{"location":"vehicle-management/#creating-vehicles","text":"To request a vehicle to be added to the database, make a POST request to the /api/vehicle endpoint, for example with the following CURL: curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{ \"vessel_type\": \"SDA\", \"max_speed\": 26.5, \"unit\": \"km/hr\", \"beam\": 24.0, \"hull_type\": \"slender\", \"force_limit\": 96634.5, \"max_ice_conc\": 80, \"min_depth\": 10 }' \\ http://localhost:8000/api/vehicle This will create a vehicle of vessel_type \"SDA\" in the database. Note that vessel_type is unique, and any subsequent request to create the same vessel type will result in an error.","title":"Creating vehicles"},{"location":"vehicle-management/#updating-vehicle-properties","text":"Should you wish to update a vessel_type 's properties after creation, you can do so using the force_properties argument in your request. Let's say we actually wanted to display the speed in knots: curl --header \"Content-Type: application/json\" \\ --request POST \\ --data '{ \"vessel_type\": \"SDA\", \"max_speed\": 14.3, \"unit\": \"knots\", \"beam\": 24.0, \"hull_type\": \"slender\", \"force_limit\": 96634.5, \"max_ice_conc\": 80, \"min_depth\": 10, \"force_properties\":\"true\" }' \\ http://localhost:8000/api/vehicle With \"force_properties\" set to \"true\" , the request will be accepted and the properties for \"SDA\" will be updated.","title":"Updating vehicle properties"},{"location":"vehicle-management/#requesting-a-list-of-all-available-vehicles","text":"To request a list of all available vehicles in the database, you can make a GET request to the api/vehicle/available endpoint: curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/vehicle/available","title":"Requesting a list of all available vehicles"},{"location":"vehicle-management/#requesting-vehicles","text":"","title":"Requesting vehicles"},{"location":"vehicle-management/#requesting-a-specific-vehicle","text":"To request a specific vehicle to be returned, you can make a GET request to the api/vehicle endpoint, adding the vessel_type to the end of the endpoint, for example api/vehicle/SDA : curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/vehicle/SDA/","title":"Requesting a specific vehicle"},{"location":"vehicle-management/#requesting-all-vehicles","text":"If you make a GET request to api/vehicle without specifying the vessel_type , all vehicles will be returned. curl --header \"Content-Type: application/json\" \\ --request GET \\ http://localhost:8000/api/vehicle","title":"Requesting all vehicles"},{"location":"vehicle-management/#deleting-a-vehicle","text":"To request a vehicle to be removed from the database, you can make a DELETE request to api/vehicle , specifying the vessel_type in the URL, just as with specific vehicle GET requests, api/vehicle/SDA : curl --header \"Content-Type: application/json\" \\ --request DELETE \\ http://localhost:8000/api/vehicle/SDA/ Removing all vehicles in one go is not currently supported.","title":"Deleting a vehicle"},{"location":"vehicle-management/#adding-a-vehicle-to-an-environment-mesh","text":"Coming soon.","title":"Adding a vehicle to an environment mesh"},{"location":"autoapi/summary/","text":"polarrouteserver route_api models responses serializers tasks utils views utils loggers request_route request_route","title":"Summary"},{"location":"autoapi/polarrouteserver/","text":"","title":"polarrouteserver"},{"location":"autoapi/polarrouteserver/route_api/","text":"","title":"route_api"},{"location":"autoapi/polarrouteserver/route_api/models/","text":"Job Bases: Model Route or mesh calculation jobs Source code in polarrouteserver/route_api/models.py class Job(models.Model): \"Route or mesh calculation jobs\" id = models.UUIDField( primary_key=True ) # use uuids for primary keys to align with celery datetime = models.DateTimeField(default=timezone.now) route = models.ForeignKey(Route, on_delete=models.CASCADE) @property def status(self): result = AsyncResult(self.id, app=app) return result.state Location Bases: Model Preset locations Source code in polarrouteserver/route_api/models.py class Location(models.Model): \"Preset locations\" lat = models.FloatField() lon = models.FloatField() name = models.CharField(max_length=100) @property def latitude(self): return self.lat @property def longitude(self): return self.lon Mesh Bases: Model Source code in polarrouteserver/route_api/models.py class Mesh(models.Model): id = models.BigAutoField(primary_key=True) meshiphi_version = models.CharField(max_length=60, null=True) md5 = models.CharField(max_length=64) valid_date_start = models.DateField() valid_date_end = models.DateField() created = models.DateTimeField() lat_min = models.FloatField() lat_max = models.FloatField() lon_min = models.FloatField() lon_max = models.FloatField() json = models.JSONField(null=True) name = models.CharField(max_length=150, null=True) @property def size(self) -> float: \"\"\"Computes a metric for the size of a mesh.\"\"\" return abs(self.lat_max - self.lat_min) * abs(self.lon_max - self.lon_min) class Meta: verbose_name_plural = \"Meshes\" size property Computes a metric for the size of a mesh.","title":"models"},{"location":"autoapi/polarrouteserver/route_api/models/#polarrouteserver.route_api.models.Job","text":"Bases: Model Route or mesh calculation jobs Source code in polarrouteserver/route_api/models.py class Job(models.Model): \"Route or mesh calculation jobs\" id = models.UUIDField( primary_key=True ) # use uuids for primary keys to align with celery datetime = models.DateTimeField(default=timezone.now) route = models.ForeignKey(Route, on_delete=models.CASCADE) @property def status(self): result = AsyncResult(self.id, app=app) return result.state","title":"Job"},{"location":"autoapi/polarrouteserver/route_api/models/#polarrouteserver.route_api.models.Location","text":"Bases: Model Preset locations Source code in polarrouteserver/route_api/models.py class Location(models.Model): \"Preset locations\" lat = models.FloatField() lon = models.FloatField() name = models.CharField(max_length=100) @property def latitude(self): return self.lat @property def longitude(self): return self.lon","title":"Location"},{"location":"autoapi/polarrouteserver/route_api/models/#polarrouteserver.route_api.models.Mesh","text":"Bases: Model Source code in polarrouteserver/route_api/models.py class Mesh(models.Model): id = models.BigAutoField(primary_key=True) meshiphi_version = models.CharField(max_length=60, null=True) md5 = models.CharField(max_length=64) valid_date_start = models.DateField() valid_date_end = models.DateField() created = models.DateTimeField() lat_min = models.FloatField() lat_max = models.FloatField() lon_min = models.FloatField() lon_max = models.FloatField() json = models.JSONField(null=True) name = models.CharField(max_length=150, null=True) @property def size(self) -> float: \"\"\"Computes a metric for the size of a mesh.\"\"\" return abs(self.lat_max - self.lat_min) * abs(self.lon_max - self.lon_min) class Meta: verbose_name_plural = \"Meshes\"","title":"Mesh"},{"location":"autoapi/polarrouteserver/route_api/models/#polarrouteserver.route_api.models.Mesh.size","text":"Computes a metric for the size of a mesh.","title":"size"},{"location":"autoapi/polarrouteserver/route_api/responses/","text":"ResponseMixin Mixin providing standardized API response methods. Ensures consistent response formatting across all API endpoints and provides response methods that correspond to the standardized schema objects defined in this module. Usage class MyView(ResponseMixin, APIView): def get(self, request): return self.success_response({\"data\": \"example\"}) Schema Integration Each method in this mixin corresponds to a schema object: - success_response() -> successResponseSchema (200) - accepted_response() -> acceptedResponseSchema (202) - no_content_response() -> noContentResponseSchema (204) - bad_request_response() -> badRequestResponseSchema (400) - not_found_response() -> notFoundResponseSchema (404) - not_acceptable_response() -> notAcceptableResponseSchema (406) Source code in polarrouteserver/route_api/responses.py class ResponseMixin: \"\"\" Mixin providing standardized API response methods. Ensures consistent response formatting across all API endpoints and provides response methods that correspond to the standardized schema objects defined in this module. Usage: class MyView(ResponseMixin, APIView): def get(self, request): return self.success_response({\"data\": \"example\"}) Schema Integration: Each method in this mixin corresponds to a schema object: - success_response() -> successResponseSchema (200) - accepted_response() -> acceptedResponseSchema (202) - no_content_response() -> noContentResponseSchema (204) - bad_request_response() -> badRequestResponseSchema (400) - not_found_response() -> notFoundResponseSchema (404) - not_acceptable_response() -> notAcceptableResponseSchema (406) \"\"\" def success_response(self, data, status_code=rest_framework.status.HTTP_200_OK): \"\"\" Return standardized success response. Corresponds to: successResponseSchema (200) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=status_code, ) def accepted_response(self, data): \"\"\" Return standardized accepted response. Corresponds to: acceptedResponseSchema (202) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_202_ACCEPTED, ) def no_content_response(self, data=None, message=None): \"\"\" Return standardized no content response. Corresponds to: noContentResponseSchema (204) \"\"\" response_data = data or {} if message: response_data[\"message\"] = message return Response( data=response_data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_204_NO_CONTENT, ) def bad_request_response( self, error_message, status_code=rest_framework.status.HTTP_400_BAD_REQUEST ): \"\"\" Return standardized bad request response. Corresponds to: badRequestResponseSchema (400) \"\"\" return Response( {\"error\": error_message}, headers={\"Content-Type\": \"application/json\"}, status=status_code, ) def not_found_response(self, message): \"\"\" Return standardized not found response. Corresponds to: notFoundResponseSchema (404) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_404_NOT_FOUND, ) def not_acceptable_response(self, message): \"\"\" Return standardized not acceptable response. Corresponds to: notAcceptableResponseSchema (406) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_406_NOT_ACCEPTABLE, ) accepted_response(data) Return standardized accepted response. Corresponds to: acceptedResponseSchema (202) Source code in polarrouteserver/route_api/responses.py def accepted_response(self, data): \"\"\" Return standardized accepted response. Corresponds to: acceptedResponseSchema (202) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_202_ACCEPTED, ) bad_request_response(error_message, status_code=rest_framework.status.HTTP_400_BAD_REQUEST) Return standardized bad request response. Corresponds to: badRequestResponseSchema (400) Source code in polarrouteserver/route_api/responses.py def bad_request_response( self, error_message, status_code=rest_framework.status.HTTP_400_BAD_REQUEST ): \"\"\" Return standardized bad request response. Corresponds to: badRequestResponseSchema (400) \"\"\" return Response( {\"error\": error_message}, headers={\"Content-Type\": \"application/json\"}, status=status_code, ) no_content_response(data=None, message=None) Return standardized no content response. Corresponds to: noContentResponseSchema (204) Source code in polarrouteserver/route_api/responses.py def no_content_response(self, data=None, message=None): \"\"\" Return standardized no content response. Corresponds to: noContentResponseSchema (204) \"\"\" response_data = data or {} if message: response_data[\"message\"] = message return Response( data=response_data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_204_NO_CONTENT, ) not_acceptable_response(message) Return standardized not acceptable response. Corresponds to: notAcceptableResponseSchema (406) Source code in polarrouteserver/route_api/responses.py def not_acceptable_response(self, message): \"\"\" Return standardized not acceptable response. Corresponds to: notAcceptableResponseSchema (406) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_406_NOT_ACCEPTABLE, ) not_found_response(message) Return standardized not found response. Corresponds to: notFoundResponseSchema (404) Source code in polarrouteserver/route_api/responses.py def not_found_response(self, message): \"\"\" Return standardized not found response. Corresponds to: notFoundResponseSchema (404) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_404_NOT_FOUND, ) success_response(data, status_code=rest_framework.status.HTTP_200_OK) Return standardized success response. Corresponds to: successResponseSchema (200) Source code in polarrouteserver/route_api/responses.py def success_response(self, data, status_code=rest_framework.status.HTTP_200_OK): \"\"\" Return standardized success response. Corresponds to: successResponseSchema (200) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=status_code, )","title":"responses"},{"location":"autoapi/polarrouteserver/route_api/responses/#polarrouteserver.route_api.responses.ResponseMixin","text":"Mixin providing standardized API response methods. Ensures consistent response formatting across all API endpoints and provides response methods that correspond to the standardized schema objects defined in this module. Usage class MyView(ResponseMixin, APIView): def get(self, request): return self.success_response({\"data\": \"example\"}) Schema Integration Each method in this mixin corresponds to a schema object: - success_response() -> successResponseSchema (200) - accepted_response() -> acceptedResponseSchema (202) - no_content_response() -> noContentResponseSchema (204) - bad_request_response() -> badRequestResponseSchema (400) - not_found_response() -> notFoundResponseSchema (404) - not_acceptable_response() -> notAcceptableResponseSchema (406) Source code in polarrouteserver/route_api/responses.py class ResponseMixin: \"\"\" Mixin providing standardized API response methods. Ensures consistent response formatting across all API endpoints and provides response methods that correspond to the standardized schema objects defined in this module. Usage: class MyView(ResponseMixin, APIView): def get(self, request): return self.success_response({\"data\": \"example\"}) Schema Integration: Each method in this mixin corresponds to a schema object: - success_response() -> successResponseSchema (200) - accepted_response() -> acceptedResponseSchema (202) - no_content_response() -> noContentResponseSchema (204) - bad_request_response() -> badRequestResponseSchema (400) - not_found_response() -> notFoundResponseSchema (404) - not_acceptable_response() -> notAcceptableResponseSchema (406) \"\"\" def success_response(self, data, status_code=rest_framework.status.HTTP_200_OK): \"\"\" Return standardized success response. Corresponds to: successResponseSchema (200) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=status_code, ) def accepted_response(self, data): \"\"\" Return standardized accepted response. Corresponds to: acceptedResponseSchema (202) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_202_ACCEPTED, ) def no_content_response(self, data=None, message=None): \"\"\" Return standardized no content response. Corresponds to: noContentResponseSchema (204) \"\"\" response_data = data or {} if message: response_data[\"message\"] = message return Response( data=response_data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_204_NO_CONTENT, ) def bad_request_response( self, error_message, status_code=rest_framework.status.HTTP_400_BAD_REQUEST ): \"\"\" Return standardized bad request response. Corresponds to: badRequestResponseSchema (400) \"\"\" return Response( {\"error\": error_message}, headers={\"Content-Type\": \"application/json\"}, status=status_code, ) def not_found_response(self, message): \"\"\" Return standardized not found response. Corresponds to: notFoundResponseSchema (404) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_404_NOT_FOUND, ) def not_acceptable_response(self, message): \"\"\" Return standardized not acceptable response. Corresponds to: notAcceptableResponseSchema (406) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_406_NOT_ACCEPTABLE, )","title":"ResponseMixin"},{"location":"autoapi/polarrouteserver/route_api/responses/#polarrouteserver.route_api.responses.ResponseMixin.accepted_response","text":"Return standardized accepted response. Corresponds to: acceptedResponseSchema (202) Source code in polarrouteserver/route_api/responses.py def accepted_response(self, data): \"\"\" Return standardized accepted response. Corresponds to: acceptedResponseSchema (202) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_202_ACCEPTED, )","title":"accepted_response"},{"location":"autoapi/polarrouteserver/route_api/responses/#polarrouteserver.route_api.responses.ResponseMixin.bad_request_response","text":"Return standardized bad request response. Corresponds to: badRequestResponseSchema (400) Source code in polarrouteserver/route_api/responses.py def bad_request_response( self, error_message, status_code=rest_framework.status.HTTP_400_BAD_REQUEST ): \"\"\" Return standardized bad request response. Corresponds to: badRequestResponseSchema (400) \"\"\" return Response( {\"error\": error_message}, headers={\"Content-Type\": \"application/json\"}, status=status_code, )","title":"bad_request_response"},{"location":"autoapi/polarrouteserver/route_api/responses/#polarrouteserver.route_api.responses.ResponseMixin.no_content_response","text":"Return standardized no content response. Corresponds to: noContentResponseSchema (204) Source code in polarrouteserver/route_api/responses.py def no_content_response(self, data=None, message=None): \"\"\" Return standardized no content response. Corresponds to: noContentResponseSchema (204) \"\"\" response_data = data or {} if message: response_data[\"message\"] = message return Response( data=response_data, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_204_NO_CONTENT, )","title":"no_content_response"},{"location":"autoapi/polarrouteserver/route_api/responses/#polarrouteserver.route_api.responses.ResponseMixin.not_acceptable_response","text":"Return standardized not acceptable response. Corresponds to: notAcceptableResponseSchema (406) Source code in polarrouteserver/route_api/responses.py def not_acceptable_response(self, message): \"\"\" Return standardized not acceptable response. Corresponds to: notAcceptableResponseSchema (406) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_406_NOT_ACCEPTABLE, )","title":"not_acceptable_response"},{"location":"autoapi/polarrouteserver/route_api/responses/#polarrouteserver.route_api.responses.ResponseMixin.not_found_response","text":"Return standardized not found response. Corresponds to: notFoundResponseSchema (404) Source code in polarrouteserver/route_api/responses.py def not_found_response(self, message): \"\"\" Return standardized not found response. Corresponds to: notFoundResponseSchema (404) \"\"\" return Response( {\"error\": message}, headers={\"Content-Type\": \"application/json\"}, status=rest_framework.status.HTTP_404_NOT_FOUND, )","title":"not_found_response"},{"location":"autoapi/polarrouteserver/route_api/responses/#polarrouteserver.route_api.responses.ResponseMixin.success_response","text":"Return standardized success response. Corresponds to: successResponseSchema (200) Source code in polarrouteserver/route_api/responses.py def success_response(self, data, status_code=rest_framework.status.HTTP_200_OK): \"\"\" Return standardized success response. Corresponds to: successResponseSchema (200) \"\"\" return Response( data, headers={\"Content-Type\": \"application/json\"}, status=status_code, )","title":"success_response"},{"location":"autoapi/polarrouteserver/route_api/serializers/","text":"JobStatusSerializer Bases: ModelSerializer Serializer for job status responses with dynamic status and route URL. The status field returns Celery task states: - PENDING: Task is waiting for execution or unknown task id - STARTED: Task has been started - SUCCESS: Task executed successfully - FAILURE: Task failed with an exception - RETRY: Task is being retried after failure - REVOKED: Task was revoked/cancelled Source code in polarrouteserver/route_api/serializers.py class JobStatusSerializer(serializers.ModelSerializer): \"\"\" Serializer for job status responses with dynamic status and route URL. The status field returns Celery task states: - PENDING: Task is waiting for execution or unknown task id - STARTED: Task has been started - SUCCESS: Task executed successfully - FAILURE: Task failed with an exception - RETRY: Task is being retried after failure - REVOKED: Task was revoked/cancelled \"\"\" status = serializers.SerializerMethodField() route_url = serializers.SerializerMethodField() info = serializers.SerializerMethodField() route_id = serializers.CharField(source=\"route.id\", read_only=True) created = serializers.DateTimeField(source=\"datetime\", read_only=True) class Meta: model = Job fields = [ \"id\", \"status\", \"route_id\", \"created\", \"route_url\", \"info\", ] def _get_celery_result(self, obj): \"\"\"Get Celery result object for this job.\"\"\" if not hasattr(self, \"_celery_result_cache\"): self._celery_result_cache = {} if obj.id not in self._celery_result_cache: self._celery_result_cache[obj.id] = AsyncResult(id=str(obj.id), app=app) return self._celery_result_cache[obj.id] def get_status(self, obj): \"\"\"Get current job status from Celery.\"\"\" result = self._get_celery_result(obj) return result.state def get_route_url(self, obj): \"\"\"Include route URL when job is successful.\"\"\" result = self._get_celery_result(obj) if result.state == \"SUCCESS\": request = self.context.get(\"request\") if request: return reverse(\"route_detail\", args=[obj.route.id], request=request) return None def get_info(self, obj): \"\"\"Include error info when job failed.\"\"\" result = self._get_celery_result(obj) if result.state == \"FAILURE\": return obj.route.info return None def to_representation(self, instance): \"\"\"Add version to response.\"\"\" data = super().to_representation(instance) data[\"polarrouteserver-version\"] = polarrouteserver_version # Remove None values for cleaner response return {k: v for k, v in data.items() if v is not None} get_info(obj) Include error info when job failed. Source code in polarrouteserver/route_api/serializers.py def get_info(self, obj): \"\"\"Include error info when job failed.\"\"\" result = self._get_celery_result(obj) if result.state == \"FAILURE\": return obj.route.info return None get_route_url(obj) Include route URL when job is successful. Source code in polarrouteserver/route_api/serializers.py def get_route_url(self, obj): \"\"\"Include route URL when job is successful.\"\"\" result = self._get_celery_result(obj) if result.state == \"SUCCESS\": request = self.context.get(\"request\") if request: return reverse(\"route_detail\", args=[obj.route.id], request=request) return None get_status(obj) Get current job status from Celery. Source code in polarrouteserver/route_api/serializers.py def get_status(self, obj): \"\"\"Get current job status from Celery.\"\"\" result = self._get_celery_result(obj) return result.state to_representation(instance) Add version to response. Source code in polarrouteserver/route_api/serializers.py def to_representation(self, instance): \"\"\"Add version to response.\"\"\" data = super().to_representation(instance) data[\"polarrouteserver-version\"] = polarrouteserver_version # Remove None values for cleaner response return {k: v for k, v in data.items() if v is not None} RouteSerializer Bases: TaggitSerializer , ModelSerializer Source code in polarrouteserver/route_api/serializers.py class RouteSerializer(TaggitSerializer, serializers.ModelSerializer): tags = TagListSerializerField() class Meta: model = Route fields = [ \"id\", \"start_lat\", \"start_lon\", \"end_lat\", \"end_lon\", \"start_name\", \"end_name\", \"json\", \"json_unsmoothed\", \"polar_route_version\", \"info\", \"mesh\", \"requested\", \"calculated\", \"tags\", ] def _extract_routes_by_type(self, route_data, route_type): \"\"\"Extract routes of a specific optimisation type from route data.\"\"\" if route_data is None: return [] return [ x for x in route_data if ( x and len(x) > 0 and isinstance(x[0], dict) and x[0].get(\"features\") and len(x[0][\"features\"]) > 0 and x[0][\"features\"][0].get(\"properties\", {}).get(\"objective_function\") == route_type ) ] def _build_optimisation_metrics(self, route_type, properties): \"\"\"Build all available metrics from route properties.\"\"\" metrics = {} total_traveltime = properties.get(\"total_traveltime\") if total_traveltime is not None: metrics[\"time\"] = {\"duration\": str(total_traveltime)} total_fuel = properties.get(\"total_fuel\") if total_fuel is not None: metrics[\"fuelConsumption\"] = { \"value\": total_fuel, \"units\": properties.get(\"fuel_units\") or \"tons\", } distance_data = properties.get(\"distance\") if distance_data and isinstance(distance_data, list) and len(distance_data) > 0: # Take the last value which should be the total distance total_distance = distance_data[-1] metrics[\"distance\"] = {\"value\": total_distance, \"units\": \"meters\"} return metrics def _build_mesh_info(self, instance): \"\"\"Build mesh information from the route instance.\"\"\" if not instance.mesh: return None return { \"id\": instance.mesh.id, \"name\": instance.mesh.name, \"validDateStart\": instance.mesh.valid_date_start.isoformat() if instance.mesh.valid_date_start else None, \"validDateEnd\": instance.mesh.valid_date_end.isoformat() if instance.mesh.valid_date_end else None, \"bounds\": { \"latMin\": instance.mesh.lat_min, \"latMax\": instance.mesh.lat_max, \"lonMin\": instance.mesh.lon_min, \"lonMax\": instance.mesh.lon_max, }, } def to_representation(self, instance): \"\"\"Transform route data into structured format.\"\"\" data = super().to_representation(instance) # Extract and organise route data by optimisation type smoothed_routes = {} unsmoothed_routes = {} for route_type in (\"traveltime\", \"fuel\"): smoothed_routes[route_type] = self._extract_routes_by_type( data[\"json\"], route_type ) unsmoothed_routes[route_type] = self._extract_routes_by_type( data[\"json_unsmoothed\"], route_type ) # Build structured response for each available route type available_routes = [] for route_type in (\"traveltime\", \"fuel\"): smoothed = smoothed_routes[route_type] unsmoothed = unsmoothed_routes[route_type] # Determine which route to use (smoothed preferred, fallback to unsmoothed) route_geojson = None unsmoothed_geojson = None info_message = None if len(smoothed) > 0: route_geojson = smoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure unsmoothed_geojson = unsmoothed[0][0] if len(unsmoothed) > 0 else None elif len(unsmoothed) > 0: route_geojson = unsmoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure info_message = { \"warning\": f\"Smoothing failed for {route_type}-optimisation, returning unsmoothed route.\" } else: # No route available for this type - skip it continue # Extract optimisation metrics from route properties properties = ( route_geojson[\"features\"][0].get(\"properties\", {}) if route_geojson else {} ) optimisation_metrics = self._build_optimisation_metrics( route_type, properties ) # Build mesh information mesh_info = self._build_mesh_info(instance) # Build structured route object route_obj = { \"type\": route_type, \"id\": str(instance.id), \"name\": f\"{data.get('start_name') or 'Start'} to {data.get('end_name') or 'End'} ({route_type})\", \"job\": { \"requestedAt\": data[\"requested\"], \"calculatedAt\": data[\"calculated\"], }, \"waypoints\": { \"start\": { \"lat\": data[\"start_lat\"], \"lon\": data[\"start_lon\"], \"name\": data.get(\"start_name\"), }, \"end\": { \"lat\": data[\"end_lat\"], \"lon\": data[\"end_lon\"], \"name\": data.get(\"end_name\"), }, }, \"path\": route_geojson, \"unsmoothedPath\": unsmoothed_geojson, \"optimisation\": {\"metrics\": optimisation_metrics}, } if mesh_info: route_obj[\"mesh\"] = mesh_info # Add any info/warnings if info_message: route_obj[\"info\"] = info_message elif data.get(\"info\"): route_obj[\"info\"] = data[\"info\"] available_routes.append(route_obj) # Always return consistent structure - routes array with version result = { \"routes\": available_routes, \"polarrouteserver-version\": polarrouteserver_version, \"tags\": data.get(\"tags\", []), } # Add error if no routes available if len(available_routes) == 0: result[\"error\"] = \"No routes available for any optimisation type.\" return result to_representation(instance) Transform route data into structured format. Source code in polarrouteserver/route_api/serializers.py def to_representation(self, instance): \"\"\"Transform route data into structured format.\"\"\" data = super().to_representation(instance) # Extract and organise route data by optimisation type smoothed_routes = {} unsmoothed_routes = {} for route_type in (\"traveltime\", \"fuel\"): smoothed_routes[route_type] = self._extract_routes_by_type( data[\"json\"], route_type ) unsmoothed_routes[route_type] = self._extract_routes_by_type( data[\"json_unsmoothed\"], route_type ) # Build structured response for each available route type available_routes = [] for route_type in (\"traveltime\", \"fuel\"): smoothed = smoothed_routes[route_type] unsmoothed = unsmoothed_routes[route_type] # Determine which route to use (smoothed preferred, fallback to unsmoothed) route_geojson = None unsmoothed_geojson = None info_message = None if len(smoothed) > 0: route_geojson = smoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure unsmoothed_geojson = unsmoothed[0][0] if len(unsmoothed) > 0 else None elif len(unsmoothed) > 0: route_geojson = unsmoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure info_message = { \"warning\": f\"Smoothing failed for {route_type}-optimisation, returning unsmoothed route.\" } else: # No route available for this type - skip it continue # Extract optimisation metrics from route properties properties = ( route_geojson[\"features\"][0].get(\"properties\", {}) if route_geojson else {} ) optimisation_metrics = self._build_optimisation_metrics( route_type, properties ) # Build mesh information mesh_info = self._build_mesh_info(instance) # Build structured route object route_obj = { \"type\": route_type, \"id\": str(instance.id), \"name\": f\"{data.get('start_name') or 'Start'} to {data.get('end_name') or 'End'} ({route_type})\", \"job\": { \"requestedAt\": data[\"requested\"], \"calculatedAt\": data[\"calculated\"], }, \"waypoints\": { \"start\": { \"lat\": data[\"start_lat\"], \"lon\": data[\"start_lon\"], \"name\": data.get(\"start_name\"), }, \"end\": { \"lat\": data[\"end_lat\"], \"lon\": data[\"end_lon\"], \"name\": data.get(\"end_name\"), }, }, \"path\": route_geojson, \"unsmoothedPath\": unsmoothed_geojson, \"optimisation\": {\"metrics\": optimisation_metrics}, } if mesh_info: route_obj[\"mesh\"] = mesh_info # Add any info/warnings if info_message: route_obj[\"info\"] = info_message elif data.get(\"info\"): route_obj[\"info\"] = data[\"info\"] available_routes.append(route_obj) # Always return consistent structure - routes array with version result = { \"routes\": available_routes, \"polarrouteserver-version\": polarrouteserver_version, \"tags\": data.get(\"tags\", []), } # Add error if no routes available if len(available_routes) == 0: result[\"error\"] = \"No routes available for any optimisation type.\" return result","title":"serializers"},{"location":"autoapi/polarrouteserver/route_api/serializers/#polarrouteserver.route_api.serializers.JobStatusSerializer","text":"Bases: ModelSerializer Serializer for job status responses with dynamic status and route URL. The status field returns Celery task states: - PENDING: Task is waiting for execution or unknown task id - STARTED: Task has been started - SUCCESS: Task executed successfully - FAILURE: Task failed with an exception - RETRY: Task is being retried after failure - REVOKED: Task was revoked/cancelled Source code in polarrouteserver/route_api/serializers.py class JobStatusSerializer(serializers.ModelSerializer): \"\"\" Serializer for job status responses with dynamic status and route URL. The status field returns Celery task states: - PENDING: Task is waiting for execution or unknown task id - STARTED: Task has been started - SUCCESS: Task executed successfully - FAILURE: Task failed with an exception - RETRY: Task is being retried after failure - REVOKED: Task was revoked/cancelled \"\"\" status = serializers.SerializerMethodField() route_url = serializers.SerializerMethodField() info = serializers.SerializerMethodField() route_id = serializers.CharField(source=\"route.id\", read_only=True) created = serializers.DateTimeField(source=\"datetime\", read_only=True) class Meta: model = Job fields = [ \"id\", \"status\", \"route_id\", \"created\", \"route_url\", \"info\", ] def _get_celery_result(self, obj): \"\"\"Get Celery result object for this job.\"\"\" if not hasattr(self, \"_celery_result_cache\"): self._celery_result_cache = {} if obj.id not in self._celery_result_cache: self._celery_result_cache[obj.id] = AsyncResult(id=str(obj.id), app=app) return self._celery_result_cache[obj.id] def get_status(self, obj): \"\"\"Get current job status from Celery.\"\"\" result = self._get_celery_result(obj) return result.state def get_route_url(self, obj): \"\"\"Include route URL when job is successful.\"\"\" result = self._get_celery_result(obj) if result.state == \"SUCCESS\": request = self.context.get(\"request\") if request: return reverse(\"route_detail\", args=[obj.route.id], request=request) return None def get_info(self, obj): \"\"\"Include error info when job failed.\"\"\" result = self._get_celery_result(obj) if result.state == \"FAILURE\": return obj.route.info return None def to_representation(self, instance): \"\"\"Add version to response.\"\"\" data = super().to_representation(instance) data[\"polarrouteserver-version\"] = polarrouteserver_version # Remove None values for cleaner response return {k: v for k, v in data.items() if v is not None}","title":"JobStatusSerializer"},{"location":"autoapi/polarrouteserver/route_api/serializers/#polarrouteserver.route_api.serializers.JobStatusSerializer.get_info","text":"Include error info when job failed. Source code in polarrouteserver/route_api/serializers.py def get_info(self, obj): \"\"\"Include error info when job failed.\"\"\" result = self._get_celery_result(obj) if result.state == \"FAILURE\": return obj.route.info return None","title":"get_info"},{"location":"autoapi/polarrouteserver/route_api/serializers/#polarrouteserver.route_api.serializers.JobStatusSerializer.get_route_url","text":"Include route URL when job is successful. Source code in polarrouteserver/route_api/serializers.py def get_route_url(self, obj): \"\"\"Include route URL when job is successful.\"\"\" result = self._get_celery_result(obj) if result.state == \"SUCCESS\": request = self.context.get(\"request\") if request: return reverse(\"route_detail\", args=[obj.route.id], request=request) return None","title":"get_route_url"},{"location":"autoapi/polarrouteserver/route_api/serializers/#polarrouteserver.route_api.serializers.JobStatusSerializer.get_status","text":"Get current job status from Celery. Source code in polarrouteserver/route_api/serializers.py def get_status(self, obj): \"\"\"Get current job status from Celery.\"\"\" result = self._get_celery_result(obj) return result.state","title":"get_status"},{"location":"autoapi/polarrouteserver/route_api/serializers/#polarrouteserver.route_api.serializers.JobStatusSerializer.to_representation","text":"Add version to response. Source code in polarrouteserver/route_api/serializers.py def to_representation(self, instance): \"\"\"Add version to response.\"\"\" data = super().to_representation(instance) data[\"polarrouteserver-version\"] = polarrouteserver_version # Remove None values for cleaner response return {k: v for k, v in data.items() if v is not None}","title":"to_representation"},{"location":"autoapi/polarrouteserver/route_api/serializers/#polarrouteserver.route_api.serializers.RouteSerializer","text":"Bases: TaggitSerializer , ModelSerializer Source code in polarrouteserver/route_api/serializers.py class RouteSerializer(TaggitSerializer, serializers.ModelSerializer): tags = TagListSerializerField() class Meta: model = Route fields = [ \"id\", \"start_lat\", \"start_lon\", \"end_lat\", \"end_lon\", \"start_name\", \"end_name\", \"json\", \"json_unsmoothed\", \"polar_route_version\", \"info\", \"mesh\", \"requested\", \"calculated\", \"tags\", ] def _extract_routes_by_type(self, route_data, route_type): \"\"\"Extract routes of a specific optimisation type from route data.\"\"\" if route_data is None: return [] return [ x for x in route_data if ( x and len(x) > 0 and isinstance(x[0], dict) and x[0].get(\"features\") and len(x[0][\"features\"]) > 0 and x[0][\"features\"][0].get(\"properties\", {}).get(\"objective_function\") == route_type ) ] def _build_optimisation_metrics(self, route_type, properties): \"\"\"Build all available metrics from route properties.\"\"\" metrics = {} total_traveltime = properties.get(\"total_traveltime\") if total_traveltime is not None: metrics[\"time\"] = {\"duration\": str(total_traveltime)} total_fuel = properties.get(\"total_fuel\") if total_fuel is not None: metrics[\"fuelConsumption\"] = { \"value\": total_fuel, \"units\": properties.get(\"fuel_units\") or \"tons\", } distance_data = properties.get(\"distance\") if distance_data and isinstance(distance_data, list) and len(distance_data) > 0: # Take the last value which should be the total distance total_distance = distance_data[-1] metrics[\"distance\"] = {\"value\": total_distance, \"units\": \"meters\"} return metrics def _build_mesh_info(self, instance): \"\"\"Build mesh information from the route instance.\"\"\" if not instance.mesh: return None return { \"id\": instance.mesh.id, \"name\": instance.mesh.name, \"validDateStart\": instance.mesh.valid_date_start.isoformat() if instance.mesh.valid_date_start else None, \"validDateEnd\": instance.mesh.valid_date_end.isoformat() if instance.mesh.valid_date_end else None, \"bounds\": { \"latMin\": instance.mesh.lat_min, \"latMax\": instance.mesh.lat_max, \"lonMin\": instance.mesh.lon_min, \"lonMax\": instance.mesh.lon_max, }, } def to_representation(self, instance): \"\"\"Transform route data into structured format.\"\"\" data = super().to_representation(instance) # Extract and organise route data by optimisation type smoothed_routes = {} unsmoothed_routes = {} for route_type in (\"traveltime\", \"fuel\"): smoothed_routes[route_type] = self._extract_routes_by_type( data[\"json\"], route_type ) unsmoothed_routes[route_type] = self._extract_routes_by_type( data[\"json_unsmoothed\"], route_type ) # Build structured response for each available route type available_routes = [] for route_type in (\"traveltime\", \"fuel\"): smoothed = smoothed_routes[route_type] unsmoothed = unsmoothed_routes[route_type] # Determine which route to use (smoothed preferred, fallback to unsmoothed) route_geojson = None unsmoothed_geojson = None info_message = None if len(smoothed) > 0: route_geojson = smoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure unsmoothed_geojson = unsmoothed[0][0] if len(unsmoothed) > 0 else None elif len(unsmoothed) > 0: route_geojson = unsmoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure info_message = { \"warning\": f\"Smoothing failed for {route_type}-optimisation, returning unsmoothed route.\" } else: # No route available for this type - skip it continue # Extract optimisation metrics from route properties properties = ( route_geojson[\"features\"][0].get(\"properties\", {}) if route_geojson else {} ) optimisation_metrics = self._build_optimisation_metrics( route_type, properties ) # Build mesh information mesh_info = self._build_mesh_info(instance) # Build structured route object route_obj = { \"type\": route_type, \"id\": str(instance.id), \"name\": f\"{data.get('start_name') or 'Start'} to {data.get('end_name') or 'End'} ({route_type})\", \"job\": { \"requestedAt\": data[\"requested\"], \"calculatedAt\": data[\"calculated\"], }, \"waypoints\": { \"start\": { \"lat\": data[\"start_lat\"], \"lon\": data[\"start_lon\"], \"name\": data.get(\"start_name\"), }, \"end\": { \"lat\": data[\"end_lat\"], \"lon\": data[\"end_lon\"], \"name\": data.get(\"end_name\"), }, }, \"path\": route_geojson, \"unsmoothedPath\": unsmoothed_geojson, \"optimisation\": {\"metrics\": optimisation_metrics}, } if mesh_info: route_obj[\"mesh\"] = mesh_info # Add any info/warnings if info_message: route_obj[\"info\"] = info_message elif data.get(\"info\"): route_obj[\"info\"] = data[\"info\"] available_routes.append(route_obj) # Always return consistent structure - routes array with version result = { \"routes\": available_routes, \"polarrouteserver-version\": polarrouteserver_version, \"tags\": data.get(\"tags\", []), } # Add error if no routes available if len(available_routes) == 0: result[\"error\"] = \"No routes available for any optimisation type.\" return result","title":"RouteSerializer"},{"location":"autoapi/polarrouteserver/route_api/serializers/#polarrouteserver.route_api.serializers.RouteSerializer.to_representation","text":"Transform route data into structured format. Source code in polarrouteserver/route_api/serializers.py def to_representation(self, instance): \"\"\"Transform route data into structured format.\"\"\" data = super().to_representation(instance) # Extract and organise route data by optimisation type smoothed_routes = {} unsmoothed_routes = {} for route_type in (\"traveltime\", \"fuel\"): smoothed_routes[route_type] = self._extract_routes_by_type( data[\"json\"], route_type ) unsmoothed_routes[route_type] = self._extract_routes_by_type( data[\"json_unsmoothed\"], route_type ) # Build structured response for each available route type available_routes = [] for route_type in (\"traveltime\", \"fuel\"): smoothed = smoothed_routes[route_type] unsmoothed = unsmoothed_routes[route_type] # Determine which route to use (smoothed preferred, fallback to unsmoothed) route_geojson = None unsmoothed_geojson = None info_message = None if len(smoothed) > 0: route_geojson = smoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure unsmoothed_geojson = unsmoothed[0][0] if len(unsmoothed) > 0 else None elif len(unsmoothed) > 0: route_geojson = unsmoothed[0][ 0 ] # Extract the actual GeoJSON from the nested structure info_message = { \"warning\": f\"Smoothing failed for {route_type}-optimisation, returning unsmoothed route.\" } else: # No route available for this type - skip it continue # Extract optimisation metrics from route properties properties = ( route_geojson[\"features\"][0].get(\"properties\", {}) if route_geojson else {} ) optimisation_metrics = self._build_optimisation_metrics( route_type, properties ) # Build mesh information mesh_info = self._build_mesh_info(instance) # Build structured route object route_obj = { \"type\": route_type, \"id\": str(instance.id), \"name\": f\"{data.get('start_name') or 'Start'} to {data.get('end_name') or 'End'} ({route_type})\", \"job\": { \"requestedAt\": data[\"requested\"], \"calculatedAt\": data[\"calculated\"], }, \"waypoints\": { \"start\": { \"lat\": data[\"start_lat\"], \"lon\": data[\"start_lon\"], \"name\": data.get(\"start_name\"), }, \"end\": { \"lat\": data[\"end_lat\"], \"lon\": data[\"end_lon\"], \"name\": data.get(\"end_name\"), }, }, \"path\": route_geojson, \"unsmoothedPath\": unsmoothed_geojson, \"optimisation\": {\"metrics\": optimisation_metrics}, } if mesh_info: route_obj[\"mesh\"] = mesh_info # Add any info/warnings if info_message: route_obj[\"info\"] = info_message elif data.get(\"info\"): route_obj[\"info\"] = data[\"info\"] available_routes.append(route_obj) # Always return consistent structure - routes array with version result = { \"routes\": available_routes, \"polarrouteserver-version\": polarrouteserver_version, \"tags\": data.get(\"tags\", []), } # Add error if no routes available if len(available_routes) == 0: result[\"error\"] = \"No routes available for any optimisation type.\" return result","title":"to_representation"},{"location":"autoapi/polarrouteserver/route_api/tasks/","text":"import_new_meshes(self) Look for new meshes and insert them into the database. Source code in polarrouteserver/route_api/tasks.py @app.task(bind=True) def import_new_meshes(self): \"\"\"Look for new meshes and insert them into the database.\"\"\" if settings.MESH_METADATA_DIR is None: raise ValueError(\"MESH_METADATA_DIR has not been set.\") # find the latest metadata file files = os.listdir(settings.MESH_METADATA_DIR) file_list = [ os.path.join(settings.MESH_METADATA_DIR, file) for file in files if file.startswith(\"upload_metadata\") and file.endswith(\".yaml.gz\") ] if len(file_list) == 0: msg = \"Upload metadata file not found.\" logger.error(msg) return latest_metadata_file = max(file_list, key=os.path.getctime) # load in the metadata logger.info( f\"Loading metadata file from {os.path.join(settings.MESH_METADATA_DIR, latest_metadata_file)}\" ) with gzip.open(latest_metadata_file, \"rb\") as f: metadata = yaml.load(f.read(), Loader=yaml.Loader) meshes_added = [] for record in metadata[\"records\"]: # we only want the vessel json files if not bool(re.search(VESSEL_MESH_FILENAME_PATTERN, record[\"filepath\"])): continue # extract the filename from the filepath mesh_filename = record[\"filepath\"].split(\"/\")[-1] # load in the mesh json try: zipped_filename = mesh_filename + \".gz\" with gzip.open( Path(settings.MESH_DIR, zipped_filename), \"rb\" ) as gzipped_mesh: mesh_json = json.load(gzipped_mesh) except FileNotFoundError: logger.warning(f\"{zipped_filename} not found. Skipping.\") continue except PermissionError: logger.warning( f\"Can't read {zipped_filename} due to permission error. File may still be transferring. Skipping.\" ) continue # write out the unzipped mesh to temp file tfile = tempfile.NamedTemporaryFile(mode=\"w+\", delete=True) json.dump(mesh_json, tfile, indent=4) tfile.flush() md5 = calculate_md5(tfile.name) # cross reference md5 hash from file record in metadata to actual file on disk if md5 != record[\"md5\"]: logger.warning( f\"Mesh file md5: {md5}\\n\\ does not match\\n\\ Metadata md5: {record['md5']}\\n\\ Skipping.\" ) # if md5 hash from metadata file does not match that of the file itself, # there may have been a filename clash, skip this one. continue # create an entry in the database mesh, created = Mesh.objects.get_or_create( md5=md5, defaults={ \"name\": mesh_filename, \"valid_date_start\": datetime.datetime.strptime( mesh_json[\"config\"][\"mesh_info\"][\"region\"][\"start_time\"], \"%Y-%m-%d\" ).replace(tzinfo=datetime.timezone.utc), \"valid_date_end\": datetime.datetime.strptime( mesh_json[\"config\"][\"mesh_info\"][\"region\"][\"end_time\"], \"%Y-%m-%d\" ).replace(tzinfo=datetime.timezone.utc), \"created\": datetime.datetime.strptime( record[\"created\"], \"%Y%m%dT%H%M%S\" ).replace(tzinfo=datetime.timezone.utc), \"json\": mesh_json, \"meshiphi_version\": record[\"meshiphi\"], \"lat_min\": record[\"latlong\"][\"latmin\"], \"lat_max\": record[\"latlong\"][\"latmax\"], \"lon_min\": record[\"latlong\"][\"lonmin\"], \"lon_max\": record[\"latlong\"][\"lonmax\"], }, ) if created: logger.info( f\"Adding new mesh to database: {mesh.id} {mesh.name} {mesh.created}\" ) meshes_added.append( {\"id\": mesh.id, \"md5\": record[\"md5\"], \"name\": mesh.name} ) return meshes_added optimise_route(self, route_id, backup_mesh_ids=None) Use PolarRoute to calculate optimal route from Route database object and mesh. Saves Route in database and returns route geojson as dictionary. Parameters: route_id ( int ) \u2013 id of record in Route database table backup_mesh_ids list \u2013 list of database ids of backup meshes to try in order of priority Returns: dict \u2013 route geojson as dictionary Source code in polarrouteserver/route_api/tasks.py @app.task(bind=True) def optimise_route( self, route_id: int, backup_mesh_ids: list[int] = None, ) -> dict: \"\"\" Use PolarRoute to calculate optimal route from Route database object and mesh. Saves Route in database and returns route geojson as dictionary. Params: route_id: id of record in Route database table backup_mesh_ids list: list of database ids of backup meshes to try in order of priority Returns: route geojson as dictionary \"\"\" route = Route.objects.get(id=route_id) mesh = route.mesh logger.info(f\"Running optimisation for route {route.id}\") logger.info(f\"Using mesh {mesh.id}\") if backup_mesh_ids: logger.info(f\"Also got backup mesh ids {backup_mesh_ids}\") # add warning on mesh date if older than today if mesh.created.date() < datetime.datetime.now().date(): route.info = { \"info\": f\"Latest available mesh from {datetime.datetime.strftime(mesh.created, '%Y/%m/%d %H:%M%S')}\" } data_warning_message = check_mesh_data(mesh) if data_warning_message != \"\": if route.info is None: route.info = {\"info\": data_warning_message} else: route.info[\"info\"] = route.info[\"info\"] + data_warning_message # convert waypoints into pandas dataframe for PolarRoute waypoints = pd.DataFrame( { \"Name\": [ \"Start\" if route.start_name is None else route.start_name, \"End\" if route.end_name is None else route.end_name, ], \"Lat\": [route.start_lat, route.end_lat], \"Long\": [route.start_lon, route.end_lon], \"Source\": [\"X\", np.nan], \"Destination\": [np.nan, \"X\"], } ) try: unsmoothed_routes = [] route_planners = [] configs = ( settings.TRAVELTIME_CONFIG, settings.FUEL_CONFIG, ) for config in configs: rp = RoutePlanner(copy.deepcopy(mesh.json), config) # Calculate optimal dijkstra path between waypoints rp.compute_routes(waypoints) route_planners.append(rp) # save the initial unsmoothed route logger.info( f\"Calculating unsmoothed Dijkstra paths for {config['objective_function']}-optimised route.\" ) if len(rp.routes_dijkstra) == 0: raise ValueError(\"Inaccessible. No routes found.\") route_geojson = extract_geojson_routes(rp.to_json()) route_geojson[0][\"features\"][0][\"properties\"][\"objective_function\"] = ( config[\"objective_function\"] ) unsmoothed_routes.append(route_geojson) # Save unsmoothed routes (but don't set calculated timestamp yet) route.json_unsmoothed = unsmoothed_routes route.polar_route_version = polar_route.__version__ route.save() # Save progress but no calculated timestamp smoothed_routes = [] for i, rp in enumerate(route_planners): # Smooth the dijkstra routes rp.compute_smoothed_routes() # Save the smoothed route(s) logger.info(f\"Route smoothing {i + 1}/{len(route_planners)} complete.\") route_geojson = extract_geojson_routes(rp.to_json()) route_geojson[0][\"features\"][0][\"properties\"][\"objective_function\"] = ( rp.config[\"objective_function\"] ) smoothed_routes.append(route_geojson) # Update the database with all routes at once route.json = smoothed_routes # Set calculated timestamp when all routes ready route.calculated = timezone.now() route.polar_route_version = polar_route.__version__ route.save() return smoothed_routes except Exception as e: logger.error(e) self.update_state(state=states.FAILURE) # this is awful, polar route should raise a custom error class if \"Inaccessible. No routes found\" in e.args[0] and len(backup_mesh_ids) > 0: # if route is inaccesible in the mesh, try again if backup meshes are provided logger.info( f\"No routes found on mesh {mesh.id}, trying with next mesh(es) {backup_mesh_ids}\" ) route.info = {\"info\": \"Route inaccessible on mesh, trying next mesh.\"} route.mesh = Mesh.objects.get(id=backup_mesh_ids[0]) route.save() task = optimise_route.delay(route.id, backup_mesh_ids[1:]) _ = Job.objects.create( id=task.id, route=route, ) raise Ignore() else: route.info = {\"error\": f\"{e}\"} route.save() raise Ignore()","title":"tasks"},{"location":"autoapi/polarrouteserver/route_api/tasks/#polarrouteserver.route_api.tasks.import_new_meshes","text":"Look for new meshes and insert them into the database. Source code in polarrouteserver/route_api/tasks.py @app.task(bind=True) def import_new_meshes(self): \"\"\"Look for new meshes and insert them into the database.\"\"\" if settings.MESH_METADATA_DIR is None: raise ValueError(\"MESH_METADATA_DIR has not been set.\") # find the latest metadata file files = os.listdir(settings.MESH_METADATA_DIR) file_list = [ os.path.join(settings.MESH_METADATA_DIR, file) for file in files if file.startswith(\"upload_metadata\") and file.endswith(\".yaml.gz\") ] if len(file_list) == 0: msg = \"Upload metadata file not found.\" logger.error(msg) return latest_metadata_file = max(file_list, key=os.path.getctime) # load in the metadata logger.info( f\"Loading metadata file from {os.path.join(settings.MESH_METADATA_DIR, latest_metadata_file)}\" ) with gzip.open(latest_metadata_file, \"rb\") as f: metadata = yaml.load(f.read(), Loader=yaml.Loader) meshes_added = [] for record in metadata[\"records\"]: # we only want the vessel json files if not bool(re.search(VESSEL_MESH_FILENAME_PATTERN, record[\"filepath\"])): continue # extract the filename from the filepath mesh_filename = record[\"filepath\"].split(\"/\")[-1] # load in the mesh json try: zipped_filename = mesh_filename + \".gz\" with gzip.open( Path(settings.MESH_DIR, zipped_filename), \"rb\" ) as gzipped_mesh: mesh_json = json.load(gzipped_mesh) except FileNotFoundError: logger.warning(f\"{zipped_filename} not found. Skipping.\") continue except PermissionError: logger.warning( f\"Can't read {zipped_filename} due to permission error. File may still be transferring. Skipping.\" ) continue # write out the unzipped mesh to temp file tfile = tempfile.NamedTemporaryFile(mode=\"w+\", delete=True) json.dump(mesh_json, tfile, indent=4) tfile.flush() md5 = calculate_md5(tfile.name) # cross reference md5 hash from file record in metadata to actual file on disk if md5 != record[\"md5\"]: logger.warning( f\"Mesh file md5: {md5}\\n\\ does not match\\n\\ Metadata md5: {record['md5']}\\n\\ Skipping.\" ) # if md5 hash from metadata file does not match that of the file itself, # there may have been a filename clash, skip this one. continue # create an entry in the database mesh, created = Mesh.objects.get_or_create( md5=md5, defaults={ \"name\": mesh_filename, \"valid_date_start\": datetime.datetime.strptime( mesh_json[\"config\"][\"mesh_info\"][\"region\"][\"start_time\"], \"%Y-%m-%d\" ).replace(tzinfo=datetime.timezone.utc), \"valid_date_end\": datetime.datetime.strptime( mesh_json[\"config\"][\"mesh_info\"][\"region\"][\"end_time\"], \"%Y-%m-%d\" ).replace(tzinfo=datetime.timezone.utc), \"created\": datetime.datetime.strptime( record[\"created\"], \"%Y%m%dT%H%M%S\" ).replace(tzinfo=datetime.timezone.utc), \"json\": mesh_json, \"meshiphi_version\": record[\"meshiphi\"], \"lat_min\": record[\"latlong\"][\"latmin\"], \"lat_max\": record[\"latlong\"][\"latmax\"], \"lon_min\": record[\"latlong\"][\"lonmin\"], \"lon_max\": record[\"latlong\"][\"lonmax\"], }, ) if created: logger.info( f\"Adding new mesh to database: {mesh.id} {mesh.name} {mesh.created}\" ) meshes_added.append( {\"id\": mesh.id, \"md5\": record[\"md5\"], \"name\": mesh.name} ) return meshes_added","title":"import_new_meshes"},{"location":"autoapi/polarrouteserver/route_api/tasks/#polarrouteserver.route_api.tasks.optimise_route","text":"Use PolarRoute to calculate optimal route from Route database object and mesh. Saves Route in database and returns route geojson as dictionary. Parameters: route_id ( int ) \u2013 id of record in Route database table backup_mesh_ids list \u2013 list of database ids of backup meshes to try in order of priority Returns: dict \u2013 route geojson as dictionary Source code in polarrouteserver/route_api/tasks.py @app.task(bind=True) def optimise_route( self, route_id: int, backup_mesh_ids: list[int] = None, ) -> dict: \"\"\" Use PolarRoute to calculate optimal route from Route database object and mesh. Saves Route in database and returns route geojson as dictionary. Params: route_id: id of record in Route database table backup_mesh_ids list: list of database ids of backup meshes to try in order of priority Returns: route geojson as dictionary \"\"\" route = Route.objects.get(id=route_id) mesh = route.mesh logger.info(f\"Running optimisation for route {route.id}\") logger.info(f\"Using mesh {mesh.id}\") if backup_mesh_ids: logger.info(f\"Also got backup mesh ids {backup_mesh_ids}\") # add warning on mesh date if older than today if mesh.created.date() < datetime.datetime.now().date(): route.info = { \"info\": f\"Latest available mesh from {datetime.datetime.strftime(mesh.created, '%Y/%m/%d %H:%M%S')}\" } data_warning_message = check_mesh_data(mesh) if data_warning_message != \"\": if route.info is None: route.info = {\"info\": data_warning_message} else: route.info[\"info\"] = route.info[\"info\"] + data_warning_message # convert waypoints into pandas dataframe for PolarRoute waypoints = pd.DataFrame( { \"Name\": [ \"Start\" if route.start_name is None else route.start_name, \"End\" if route.end_name is None else route.end_name, ], \"Lat\": [route.start_lat, route.end_lat], \"Long\": [route.start_lon, route.end_lon], \"Source\": [\"X\", np.nan], \"Destination\": [np.nan, \"X\"], } ) try: unsmoothed_routes = [] route_planners = [] configs = ( settings.TRAVELTIME_CONFIG, settings.FUEL_CONFIG, ) for config in configs: rp = RoutePlanner(copy.deepcopy(mesh.json), config) # Calculate optimal dijkstra path between waypoints rp.compute_routes(waypoints) route_planners.append(rp) # save the initial unsmoothed route logger.info( f\"Calculating unsmoothed Dijkstra paths for {config['objective_function']}-optimised route.\" ) if len(rp.routes_dijkstra) == 0: raise ValueError(\"Inaccessible. No routes found.\") route_geojson = extract_geojson_routes(rp.to_json()) route_geojson[0][\"features\"][0][\"properties\"][\"objective_function\"] = ( config[\"objective_function\"] ) unsmoothed_routes.append(route_geojson) # Save unsmoothed routes (but don't set calculated timestamp yet) route.json_unsmoothed = unsmoothed_routes route.polar_route_version = polar_route.__version__ route.save() # Save progress but no calculated timestamp smoothed_routes = [] for i, rp in enumerate(route_planners): # Smooth the dijkstra routes rp.compute_smoothed_routes() # Save the smoothed route(s) logger.info(f\"Route smoothing {i + 1}/{len(route_planners)} complete.\") route_geojson = extract_geojson_routes(rp.to_json()) route_geojson[0][\"features\"][0][\"properties\"][\"objective_function\"] = ( rp.config[\"objective_function\"] ) smoothed_routes.append(route_geojson) # Update the database with all routes at once route.json = smoothed_routes # Set calculated timestamp when all routes ready route.calculated = timezone.now() route.polar_route_version = polar_route.__version__ route.save() return smoothed_routes except Exception as e: logger.error(e) self.update_state(state=states.FAILURE) # this is awful, polar route should raise a custom error class if \"Inaccessible. No routes found\" in e.args[0] and len(backup_mesh_ids) > 0: # if route is inaccesible in the mesh, try again if backup meshes are provided logger.info( f\"No routes found on mesh {mesh.id}, trying with next mesh(es) {backup_mesh_ids}\" ) route.info = {\"info\": \"Route inaccessible on mesh, trying next mesh.\"} route.mesh = Mesh.objects.get(id=backup_mesh_ids[0]) route.save() task = optimise_route.delay(route.id, backup_mesh_ids[1:]) _ = Job.objects.create( id=task.id, route=route, ) raise Ignore() else: route.info = {\"error\": f\"{e}\"} route.save() raise Ignore()","title":"optimise_route"},{"location":"autoapi/polarrouteserver/route_api/utils/","text":"calculate_md5(filename) create md5sum checksum for any file Source code in polarrouteserver/route_api/utils.py def calculate_md5(filename): \"\"\"create md5sum checksum for any file\"\"\" hash_md5 = hashlib.md5() with open(filename, \"rb\") as f: for chunk in iter(lambda: f.read(4096), b\"\"): hash_md5.update(chunk) return hash_md5.hexdigest() check_mesh_data(mesh) Check a mesh object for missing data sources. Parameters: mesh ( Mesh ) \u2013 mesh object to evaluate. Returns: str \u2013 A user-friendly warning message as a string. Source code in polarrouteserver/route_api/utils.py def check_mesh_data(mesh: Mesh) -> str: \"\"\"Check a mesh object for missing data sources. Args: mesh (Mesh): mesh object to evaluate. Returns: A user-friendly warning message as a string. \"\"\" message = \"\" mesh_data_sources = mesh.json[\"config\"][\"mesh_info\"].get(\"data_sources\", None) # check for completely absent data sources if mesh_data_sources is None: message = \"Mesh has no data sources.\" return message expected_sources = settings.EXPECTED_MESH_DATA_SOURCES expected_num_data_files = settings.EXPECTED_MESH_DATA_FILES for data_type, data_loader in expected_sources.items(): # check for missing individual data sources data_source = [d for d in mesh_data_sources if d[\"loader\"] == data_loader] if len(data_source) == 0: message += f\"Warning: This mesh is missing data on the following parameters: {data_type}.\\n\" # skip to the next data source continue # check for unexpected number of data files data_source_num_expected_files = expected_num_data_files.get(data_loader, None) if data_source_num_expected_files is not None: actual_num_files = len( [f for f in data_source[0][\"params\"][\"files\"] if f != \"\"] ) # number of files removing empty strings if actual_num_files != data_source_num_expected_files: message += f\"Warning: {actual_num_files} of expected {data_source_num_expected_files} days' data available for {data_type}.\\n\" return message evaluate_route(route_json, mesh) Run calculate_route method from PolarRoute to evaluate the fuel usage and travel time of a route. Parameters: route_json ( dict ) \u2013 route to evaluate in geojson format. mesh ( Mesh ) \u2013 mesh object on which to evaluate the route. Returns: dict ( dict ) \u2013 evaluated route Source code in polarrouteserver/route_api/utils.py def evaluate_route(route_json: dict, mesh: Mesh) -> dict: \"\"\"Run calculate_route method from PolarRoute to evaluate the fuel usage and travel time of a route. Args: route_json (dict): route to evaluate in geojson format. mesh (polarrouteserver.models.Mesh): mesh object on which to evaluate the route. Returns: dict: evaluated route \"\"\" if route_json[\"features\"][0].get(\"properties\", None) is None: route_json[\"features\"][0][\"properties\"] = {\"from\": \"Start\", \"to\": \"End\"} # route_calc only supports files, write out both route and mesh as temporary files route_file = NamedTemporaryFile(delete=False, suffix=\".json\") with open(route_file.name, \"w\") as fp: json.dump(route_json, fp) mesh_file = NamedTemporaryFile(delete=False, suffix=\".json\") with open(mesh_file.name, \"w\") as fp: json.dump(mesh.json, fp) try: calc_route = route_calc(route_file.name, mesh_file.name) time_days = calc_route[\"features\"][0][\"properties\"][\"traveltime\"][-1] time_str = convert_decimal_days(time_days) fuel = round(calc_route[\"features\"][0][\"properties\"][\"fuel\"][-1], 2) except Exception as e: logger.error(e) return None finally: for file in (route_file, mesh_file): try: os.remove(file.name) except Exception as e: logger.warning(f\"{file} not removed due to {e}\") return dict( route=calc_route, time_days=time_days, time_str=time_str, fuel_tonnes=fuel ) route_exists(meshes, start_lat, start_lon, end_lat, end_lon) Check if a route of given parameters has already been calculated. Works through list of meshes in order, returns first matching route Return None if not and the route object if it has. Source code in polarrouteserver/route_api/utils.py def route_exists( meshes: Union[Mesh, list[Mesh]], start_lat: float, start_lon: float, end_lat: float, end_lon: float, ) -> Union[Route, None]: \"\"\"Check if a route of given parameters has already been calculated. Works through list of meshes in order, returns first matching route Return None if not and the route object if it has. \"\"\" if isinstance(meshes, Mesh): meshes = [meshes] for mesh in meshes: same_mesh_routes = Route.objects.filter(mesh=mesh) # use set to preserve uniqueness successful_route_ids = set() # remove any failed routes for route in same_mesh_routes: # job_set can't be filtered since status is a property method for job in route.job_set.all(): # Use the model's status property if job.status != \"FAILURE\": successful_route_ids.add(route.id) successful_routes = same_mesh_routes.filter(id__in=successful_route_ids) # if there are none return None if len(successful_routes) == 0: continue else: exact_routes = successful_routes.filter( start_lat=start_lat, start_lon=start_lon, end_lat=end_lat, end_lon=end_lon, ) if len(exact_routes) == 1: return exact_routes[0] elif len(exact_routes) > 1: # TODO if multiple matching routes exist, which to return? return exact_routes[0] else: # if no exact routes, look for any that are close enough return _closest_route_in_tolerance( same_mesh_routes, start_lat, start_lon, end_lat, end_lon ) return None select_mesh(start_lat, start_lon, end_lat, end_lon) Find the most suitable mesh from the database for a given set of start and end coordinates. Returns either a list of Mesh objects or None. Source code in polarrouteserver/route_api/utils.py def select_mesh( start_lat: float, start_lon: float, end_lat: float, end_lon: float, ) -> Union[list[Mesh], None]: \"\"\"Find the most suitable mesh from the database for a given set of start and end coordinates. Returns either a list of Mesh objects or None. \"\"\" try: # get meshes which contain both start and end points containing_meshes = Mesh.objects.filter( lat_min__lte=start_lat, lat_max__gte=start_lat, lon_min__lte=start_lon, lon_max__gte=start_lon, ).filter( lat_min__lte=end_lat, lat_max__gte=end_lat, lon_min__lte=end_lon, lon_max__gte=end_lon, ) # get the date of the most recently created mesh latest_date = containing_meshes.latest(\"created\").created.date() # get all valid meshes from that creation date valid_meshes = containing_meshes.filter(created__date=latest_date) # return the smallest return sorted(valid_meshes, key=lambda mesh: mesh.size) except Mesh.DoesNotExist: return None select_mesh_for_route_evaluation(route) Select a mesh from the database to be used for route evaluation. The latest mesh containing all points in the route will be chosen. If no suitable meshes are available, return None. Parameters: route ( dict ) \u2013 GeoJSON route to be evaluated. Returns: Union [ list [ Mesh ], None] \u2013 Union[Mesh,None]: Selected mesh object or None. Source code in polarrouteserver/route_api/utils.py def select_mesh_for_route_evaluation(route: dict) -> Union[list[Mesh], None]: \"\"\"Select a mesh from the database to be used for route evaluation. The latest mesh containing all points in the route will be chosen. If no suitable meshes are available, return None. Args: route (dict): GeoJSON route to be evaluated. Returns: Union[Mesh,None]: Selected mesh object or None. \"\"\" coordinates = route[\"features\"][0][\"geometry\"][\"coordinates\"] lats = [c[0] for c in coordinates] lons = [c[1] for c in coordinates] return select_mesh(min(lats), min(lons), max(lats), max(lons))","title":"utils"},{"location":"autoapi/polarrouteserver/route_api/utils/#polarrouteserver.route_api.utils.calculate_md5","text":"create md5sum checksum for any file Source code in polarrouteserver/route_api/utils.py def calculate_md5(filename): \"\"\"create md5sum checksum for any file\"\"\" hash_md5 = hashlib.md5() with open(filename, \"rb\") as f: for chunk in iter(lambda: f.read(4096), b\"\"): hash_md5.update(chunk) return hash_md5.hexdigest()","title":"calculate_md5"},{"location":"autoapi/polarrouteserver/route_api/utils/#polarrouteserver.route_api.utils.check_mesh_data","text":"Check a mesh object for missing data sources. Parameters: mesh ( Mesh ) \u2013 mesh object to evaluate. Returns: str \u2013 A user-friendly warning message as a string. Source code in polarrouteserver/route_api/utils.py def check_mesh_data(mesh: Mesh) -> str: \"\"\"Check a mesh object for missing data sources. Args: mesh (Mesh): mesh object to evaluate. Returns: A user-friendly warning message as a string. \"\"\" message = \"\" mesh_data_sources = mesh.json[\"config\"][\"mesh_info\"].get(\"data_sources\", None) # check for completely absent data sources if mesh_data_sources is None: message = \"Mesh has no data sources.\" return message expected_sources = settings.EXPECTED_MESH_DATA_SOURCES expected_num_data_files = settings.EXPECTED_MESH_DATA_FILES for data_type, data_loader in expected_sources.items(): # check for missing individual data sources data_source = [d for d in mesh_data_sources if d[\"loader\"] == data_loader] if len(data_source) == 0: message += f\"Warning: This mesh is missing data on the following parameters: {data_type}.\\n\" # skip to the next data source continue # check for unexpected number of data files data_source_num_expected_files = expected_num_data_files.get(data_loader, None) if data_source_num_expected_files is not None: actual_num_files = len( [f for f in data_source[0][\"params\"][\"files\"] if f != \"\"] ) # number of files removing empty strings if actual_num_files != data_source_num_expected_files: message += f\"Warning: {actual_num_files} of expected {data_source_num_expected_files} days' data available for {data_type}.\\n\" return message","title":"check_mesh_data"},{"location":"autoapi/polarrouteserver/route_api/utils/#polarrouteserver.route_api.utils.evaluate_route","text":"Run calculate_route method from PolarRoute to evaluate the fuel usage and travel time of a route. Parameters: route_json ( dict ) \u2013 route to evaluate in geojson format. mesh ( Mesh ) \u2013 mesh object on which to evaluate the route. Returns: dict ( dict ) \u2013 evaluated route Source code in polarrouteserver/route_api/utils.py def evaluate_route(route_json: dict, mesh: Mesh) -> dict: \"\"\"Run calculate_route method from PolarRoute to evaluate the fuel usage and travel time of a route. Args: route_json (dict): route to evaluate in geojson format. mesh (polarrouteserver.models.Mesh): mesh object on which to evaluate the route. Returns: dict: evaluated route \"\"\" if route_json[\"features\"][0].get(\"properties\", None) is None: route_json[\"features\"][0][\"properties\"] = {\"from\": \"Start\", \"to\": \"End\"} # route_calc only supports files, write out both route and mesh as temporary files route_file = NamedTemporaryFile(delete=False, suffix=\".json\") with open(route_file.name, \"w\") as fp: json.dump(route_json, fp) mesh_file = NamedTemporaryFile(delete=False, suffix=\".json\") with open(mesh_file.name, \"w\") as fp: json.dump(mesh.json, fp) try: calc_route = route_calc(route_file.name, mesh_file.name) time_days = calc_route[\"features\"][0][\"properties\"][\"traveltime\"][-1] time_str = convert_decimal_days(time_days) fuel = round(calc_route[\"features\"][0][\"properties\"][\"fuel\"][-1], 2) except Exception as e: logger.error(e) return None finally: for file in (route_file, mesh_file): try: os.remove(file.name) except Exception as e: logger.warning(f\"{file} not removed due to {e}\") return dict( route=calc_route, time_days=time_days, time_str=time_str, fuel_tonnes=fuel )","title":"evaluate_route"},{"location":"autoapi/polarrouteserver/route_api/utils/#polarrouteserver.route_api.utils.route_exists","text":"Check if a route of given parameters has already been calculated. Works through list of meshes in order, returns first matching route Return None if not and the route object if it has. Source code in polarrouteserver/route_api/utils.py def route_exists( meshes: Union[Mesh, list[Mesh]], start_lat: float, start_lon: float, end_lat: float, end_lon: float, ) -> Union[Route, None]: \"\"\"Check if a route of given parameters has already been calculated. Works through list of meshes in order, returns first matching route Return None if not and the route object if it has. \"\"\" if isinstance(meshes, Mesh): meshes = [meshes] for mesh in meshes: same_mesh_routes = Route.objects.filter(mesh=mesh) # use set to preserve uniqueness successful_route_ids = set() # remove any failed routes for route in same_mesh_routes: # job_set can't be filtered since status is a property method for job in route.job_set.all(): # Use the model's status property if job.status != \"FAILURE\": successful_route_ids.add(route.id) successful_routes = same_mesh_routes.filter(id__in=successful_route_ids) # if there are none return None if len(successful_routes) == 0: continue else: exact_routes = successful_routes.filter( start_lat=start_lat, start_lon=start_lon, end_lat=end_lat, end_lon=end_lon, ) if len(exact_routes) == 1: return exact_routes[0] elif len(exact_routes) > 1: # TODO if multiple matching routes exist, which to return? return exact_routes[0] else: # if no exact routes, look for any that are close enough return _closest_route_in_tolerance( same_mesh_routes, start_lat, start_lon, end_lat, end_lon ) return None","title":"route_exists"},{"location":"autoapi/polarrouteserver/route_api/utils/#polarrouteserver.route_api.utils.select_mesh","text":"Find the most suitable mesh from the database for a given set of start and end coordinates. Returns either a list of Mesh objects or None. Source code in polarrouteserver/route_api/utils.py def select_mesh( start_lat: float, start_lon: float, end_lat: float, end_lon: float, ) -> Union[list[Mesh], None]: \"\"\"Find the most suitable mesh from the database for a given set of start and end coordinates. Returns either a list of Mesh objects or None. \"\"\" try: # get meshes which contain both start and end points containing_meshes = Mesh.objects.filter( lat_min__lte=start_lat, lat_max__gte=start_lat, lon_min__lte=start_lon, lon_max__gte=start_lon, ).filter( lat_min__lte=end_lat, lat_max__gte=end_lat, lon_min__lte=end_lon, lon_max__gte=end_lon, ) # get the date of the most recently created mesh latest_date = containing_meshes.latest(\"created\").created.date() # get all valid meshes from that creation date valid_meshes = containing_meshes.filter(created__date=latest_date) # return the smallest return sorted(valid_meshes, key=lambda mesh: mesh.size) except Mesh.DoesNotExist: return None","title":"select_mesh"},{"location":"autoapi/polarrouteserver/route_api/utils/#polarrouteserver.route_api.utils.select_mesh_for_route_evaluation","text":"Select a mesh from the database to be used for route evaluation. The latest mesh containing all points in the route will be chosen. If no suitable meshes are available, return None. Parameters: route ( dict ) \u2013 GeoJSON route to be evaluated. Returns: Union [ list [ Mesh ], None] \u2013 Union[Mesh,None]: Selected mesh object or None. Source code in polarrouteserver/route_api/utils.py def select_mesh_for_route_evaluation(route: dict) -> Union[list[Mesh], None]: \"\"\"Select a mesh from the database to be used for route evaluation. The latest mesh containing all points in the route will be chosen. If no suitable meshes are available, return None. Args: route (dict): GeoJSON route to be evaluated. Returns: Union[Mesh,None]: Selected mesh object or None. \"\"\" coordinates = route[\"features\"][0][\"geometry\"][\"coordinates\"] lats = [c[0] for c in coordinates] lons = [c[1] for c in coordinates] return select_mesh(min(lats), min(lons), max(lats), max(lons))","title":"select_mesh_for_route_evaluation"},{"location":"autoapi/polarrouteserver/route_api/views/","text":"EvaluateRouteView Bases: LoggingMixin , ResponseMixin , APIView Source code in polarrouteserver/route_api/views.py class EvaluateRouteView(LoggingMixin, ResponseMixin, APIView): serializer_class = None @extend_schema( operation_id=\"api_route_evaluation\", request=inline_serializer( name=\"RouteEvaluationRequest\", fields={ \"route\": serializers.JSONField(help_text=\"The route JSON to evaluate.\"), \"custom_mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for evaluation.\", ), }, ), responses={ 200: routeEvaluationResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"POST Endpoint to evaluate traveltime and fuel usage on a given route.\" data = request.data route_json = data.get(\"route\", None) custom_mesh_id = data.get(\"custom_mesh_id\", None) if custom_mesh_id: try: mesh = Mesh.objects.get(id=custom_mesh_id) meshes = [mesh] except Mesh.DoesNotExist: return self.not_found_response(\"No mesh available.\") else: meshes = select_mesh_for_route_evaluation(route_json) if meshes is None: return self.not_found_response(\"No mesh available.\") response_data = {\"polarrouteserver-version\": polarrouteserver_version} result_dict = evaluate_route(route_json, meshes[0]) if result_dict is None: result_dict = {\"error\": \"Route evaluation not possible.\"} response_data.update(result_dict) return self.success_response(response_data) post(request) POST Endpoint to evaluate traveltime and fuel usage on a given route. Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_route_evaluation\", request=inline_serializer( name=\"RouteEvaluationRequest\", fields={ \"route\": serializers.JSONField(help_text=\"The route JSON to evaluate.\"), \"custom_mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for evaluation.\", ), }, ), responses={ 200: routeEvaluationResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"POST Endpoint to evaluate traveltime and fuel usage on a given route.\" data = request.data route_json = data.get(\"route\", None) custom_mesh_id = data.get(\"custom_mesh_id\", None) if custom_mesh_id: try: mesh = Mesh.objects.get(id=custom_mesh_id) meshes = [mesh] except Mesh.DoesNotExist: return self.not_found_response(\"No mesh available.\") else: meshes = select_mesh_for_route_evaluation(route_json) if meshes is None: return self.not_found_response(\"No mesh available.\") response_data = {\"polarrouteserver-version\": polarrouteserver_version} result_dict = evaluate_route(route_json, meshes[0]) if result_dict is None: result_dict = {\"error\": \"Route evaluation not possible.\"} response_data.update(result_dict) return self.success_response(response_data) JobView Bases: LoggingMixin , ResponseMixin , GenericAPIView View for handling job status requests Source code in polarrouteserver/route_api/views.py class JobView(LoggingMixin, ResponseMixin, GenericAPIView): \"\"\" View for handling job status requests \"\"\" serializer_class = JobStatusSerializer @extend_schema( operation_id=\"api_job_retrieve_status\", responses={ 200: jobStatusResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return status of job and route URL if complete.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") serializer = JobStatusSerializer(job, context={\"request\": request}) return self.success_response(serializer.data) @extend_schema( operation_id=\"api_job_cancel\", responses={ 202: acceptedResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, id): \"\"\"Cancel job\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") # Store route ID for response before deletion route_id = job.route.id # Cancel the Celery task result = AsyncResult(id=str(id), app=app) result.revoke() # Delete the corresponding route (this will also delete the job due to CASCADE) job.route.delete() return self.accepted_response( { \"message\": f\"Job {id} cancellation requested and route {route_id} deleted.\", \"job_id\": str(job.id), \"route_id\": route_id, } ) delete(request, id) Cancel job Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_job_cancel\", responses={ 202: acceptedResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, id): \"\"\"Cancel job\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") # Store route ID for response before deletion route_id = job.route.id # Cancel the Celery task result = AsyncResult(id=str(id), app=app) result.revoke() # Delete the corresponding route (this will also delete the job due to CASCADE) job.route.delete() return self.accepted_response( { \"message\": f\"Job {id} cancellation requested and route {route_id} deleted.\", \"job_id\": str(job.id), \"route_id\": route_id, } ) get(request, id) Return status of job and route URL if complete. Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_job_retrieve_status\", responses={ 200: jobStatusResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return status of job and route URL if complete.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") serializer = JobStatusSerializer(job, context={\"request\": request}) return self.success_response(serializer.data) LoggingMixin Provides full logging of requests and responses Source code in polarrouteserver/route_api/views.py class LoggingMixin: \"\"\" Provides full logging of requests and responses \"\"\" def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.logger = logging.getLogger(\"django.request\") def initial(self, request, *args, **kwargs): try: self.logger.debug( { \"request\": request.data, \"method\": request.method, \"endpoint\": request.path, \"user\": request.user.username, \"ip_address\": request.META.get(\"REMOTE_ADDR\"), \"user_agent\": request.META.get(\"HTTP_USER_AGENT\"), } ) except Exception: self.logger.exception(\"Error logging request data\") super().initial(request, *args, **kwargs) def finalize_response(self, request, response, *args, **kwargs): try: self.logger.debug( { \"response\": response.data, \"status_code\": response.status_code, \"user\": request.user.username, \"ip_address\": request.META.get(\"REMOTE_ADDR\"), \"user_agent\": request.META.get(\"HTTP_USER_AGENT\"), } ) except Exception: self.logger.exception(\"Error logging response data\") return super().finalize_response(request, response, *args, **kwargs) MeshView Bases: LoggingMixin , ResponseMixin , APIView Source code in polarrouteserver/route_api/views.py class MeshView(LoggingMixin, ResponseMixin, APIView): serializer_class = None @extend_schema( operation_id=\"api_mesh_get\", responses={ 200: meshDetailResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"GET Meshes by id\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) data = {\"polarrouteserver-version\": polarrouteserver_version} try: mesh = Mesh.objects.get(id=id) data.update( dict( id=mesh.id, json=mesh.json, geojson=EnvironmentMesh.load_from_json(mesh.json).to_geojson(), ) ) return self.success_response(data) except Mesh.DoesNotExist: return self.not_found_response(f\"Mesh with id {id} not found.\") get(request, id) GET Meshes by id Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_mesh_get\", responses={ 200: meshDetailResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"GET Meshes by id\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) data = {\"polarrouteserver-version\": polarrouteserver_version} try: mesh = Mesh.objects.get(id=id) data.update( dict( id=mesh.id, json=mesh.json, geojson=EnvironmentMesh.load_from_json(mesh.json).to_geojson(), ) ) return self.success_response(data) except Mesh.DoesNotExist: return self.not_found_response(f\"Mesh with id {id} not found.\") RecentRoutesView Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class RecentRoutesView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = None # No serializer needed - using manual response building def _get_celery_task_status(self, job_id, calculated_timestamp, route_info): \"\"\" Get Celery task status. Uses database state to avoid Celery broker calls. \"\"\" if calculated_timestamp: return \"SUCCESS\" if route_info and \"error\" in str(route_info).lower(): return \"FAILURE\" # Handle missing job scenarios if not job_id: return \"PENDING\" # Job exists but no calculation yet - also PENDING return \"PENDING\" @extend_schema( operation_id=\"api_recent_routes_list\", responses={ 200: recentRoutesResponseSchema, }, ) def get(self, request): \"\"\"Get recent routes\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) # Only get today's routes routes_recent = ( Route.objects.filter(requested__gte=timezone.now() - timedelta(hours=24)) .select_related(\"job\") .values( \"id\", \"start_lat\", \"start_lon\", \"end_lat\", \"end_lon\", \"start_name\", \"end_name\", \"polar_route_version\", \"requested\", \"calculated\", \"info\", \"mesh_id\", \"mesh__name\", \"job__id\", ) .order_by(\"-requested\") ) if not routes_recent: return self.success_response( { \"routes\": [], \"polarrouteserver-version\": polarrouteserver_version, \"message\": \"No recent routes found for last 24 hours.\", } ) # Get route IDs for tag lookup route_ids = [route[\"id\"] for route in routes_recent] # Get all tags for routes in one query route_tags = {} if route_ids: content_type = ContentType.objects.get_for_model(Route) tagged_items = ( TaggedItem.objects.filter( content_type=content_type, object_id__in=route_ids ) .select_related(\"tag\") .values(\"object_id\", \"tag__name\") ) for item in tagged_items: route_id = int(item[\"object_id\"]) if route_id not in route_tags: route_tags[route_id] = [] route_tags[route_id].append(item[\"tag__name\"]) routes_data = [] for route in routes_recent: job_id = route.get(\"job__id\") status = self._get_celery_task_status( job_id, route[\"calculated\"], route[\"info\"] ) # Build lightweight route data route_data = { \"id\": route[\"id\"], \"start_lat\": route[\"start_lat\"], \"start_lon\": route[\"start_lon\"], \"end_lat\": route[\"end_lat\"], \"end_lon\": route[\"end_lon\"], \"start_name\": route[\"start_name\"], \"end_name\": route[\"end_name\"], \"polar_route_version\": route[\"polar_route_version\"], \"requested\": route[\"requested\"].isoformat() if route[\"requested\"] else None, \"calculated\": route[\"calculated\"].isoformat() if route[\"calculated\"] else None, \"status\": status, \"route_url\": reverse( \"route_detail\", args=[route[\"id\"]], request=request ), \"tags\": route_tags.get(route[\"id\"], []), } if job_id: route_data[\"job_id\"] = job_id route_data[\"job_status_url\"] = reverse( \"job_detail\", args=[job_id], request=request ) # Add minimal mesh info without loading the heavy JSON if route[\"mesh_id\"]: route_data[\"mesh\"] = { \"id\": route[\"mesh_id\"], \"name\": route[\"mesh__name\"], } routes_data.append(route_data) response_data = { \"routes\": routes_data, \"polarrouteserver-version\": polarrouteserver_version, } return self.success_response(response_data) get(request) Get recent routes Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_recent_routes_list\", responses={ 200: recentRoutesResponseSchema, }, ) def get(self, request): \"\"\"Get recent routes\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) # Only get today's routes routes_recent = ( Route.objects.filter(requested__gte=timezone.now() - timedelta(hours=24)) .select_related(\"job\") .values( \"id\", \"start_lat\", \"start_lon\", \"end_lat\", \"end_lon\", \"start_name\", \"end_name\", \"polar_route_version\", \"requested\", \"calculated\", \"info\", \"mesh_id\", \"mesh__name\", \"job__id\", ) .order_by(\"-requested\") ) if not routes_recent: return self.success_response( { \"routes\": [], \"polarrouteserver-version\": polarrouteserver_version, \"message\": \"No recent routes found for last 24 hours.\", } ) # Get route IDs for tag lookup route_ids = [route[\"id\"] for route in routes_recent] # Get all tags for routes in one query route_tags = {} if route_ids: content_type = ContentType.objects.get_for_model(Route) tagged_items = ( TaggedItem.objects.filter( content_type=content_type, object_id__in=route_ids ) .select_related(\"tag\") .values(\"object_id\", \"tag__name\") ) for item in tagged_items: route_id = int(item[\"object_id\"]) if route_id not in route_tags: route_tags[route_id] = [] route_tags[route_id].append(item[\"tag__name\"]) routes_data = [] for route in routes_recent: job_id = route.get(\"job__id\") status = self._get_celery_task_status( job_id, route[\"calculated\"], route[\"info\"] ) # Build lightweight route data route_data = { \"id\": route[\"id\"], \"start_lat\": route[\"start_lat\"], \"start_lon\": route[\"start_lon\"], \"end_lat\": route[\"end_lat\"], \"end_lon\": route[\"end_lon\"], \"start_name\": route[\"start_name\"], \"end_name\": route[\"end_name\"], \"polar_route_version\": route[\"polar_route_version\"], \"requested\": route[\"requested\"].isoformat() if route[\"requested\"] else None, \"calculated\": route[\"calculated\"].isoformat() if route[\"calculated\"] else None, \"status\": status, \"route_url\": reverse( \"route_detail\", args=[route[\"id\"]], request=request ), \"tags\": route_tags.get(route[\"id\"], []), } if job_id: route_data[\"job_id\"] = job_id route_data[\"job_status_url\"] = reverse( \"job_detail\", args=[job_id], request=request ) # Add minimal mesh info without loading the heavy JSON if route[\"mesh_id\"]: route_data[\"mesh\"] = { \"id\": route[\"mesh_id\"], \"name\": route[\"mesh__name\"], } routes_data.append(route_data) response_data = { \"routes\": routes_data, \"polarrouteserver-version\": polarrouteserver_version, } return self.success_response(response_data) RouteDetailView Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class RouteDetailView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = RouteSerializer @extend_schema( operation_id=\"api_route_retrieve_by_id\", description=\"Retrieve route details by ID. Returns the route data.\", responses={ 200: routeSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return route data by route ID.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: route = Route.objects.get(id=id) except Route.DoesNotExist: return self.not_found_response(f\"Route with id {id} not found.\") data = RouteSerializer(route).data return self.success_response(data) get(request, id) Return route data by route ID. Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_route_retrieve_by_id\", description=\"Retrieve route details by ID. Returns the route data.\", responses={ 200: routeSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return route data by route ID.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: route = Route.objects.get(id=id) except Route.DoesNotExist: return self.not_found_response(f\"Route with id {id} not found.\") data = RouteSerializer(route).data return self.success_response(data) RouteRequestView Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class RouteRequestView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = RouteSerializer @extend_schema( operation_id=\"api_route_create_request\", request=inline_serializer( name=\"RouteCreationRequest\", # This should be updated along with the json validation below fields={ \"start_lat\": serializers.FloatField( help_text=\"Starting latitude of the route.\" ), \"start_lon\": serializers.FloatField( help_text=\"Starting longitude of the route.\" ), \"end_lat\": serializers.FloatField( help_text=\"Ending latitude of the route.\" ), \"end_lon\": serializers.FloatField( help_text=\"Ending longitude of the route.\" ), \"start_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the start point.\", ), \"end_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the end point.\" ), \"mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for route calculation.\", ), \"force_new_route\": serializers.BooleanField( required=False, default=False, help_text=\"If true, forces recalculation even if an existing route is found.\", ), \"tags\": serializers.ListField( child=serializers.CharField(max_length=50), required=False, allow_null=True, help_text=\"Optional tags for route (e.g., ['archive', 'SD056']). Can also accept a single string or comma-separated string.\", ), }, ), responses={ 202: routeAcceptedResponseSchema, 400: badRequestResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"\"\"Entry point for route requests\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # TODO validate request JSON try: start_lat = float(data[\"start_lat\"]) start_lon = float(data[\"start_lon\"]) end_lat = float(data[\"end_lat\"]) end_lon = float(data[\"end_lon\"]) except (ValueError, TypeError, KeyError) as e: msg = f\"Invalid coordinate values provided: {e}\" logger.error(msg) return self.bad_request_response(msg) start_name = data.get(\"start_name\", None) end_name = data.get(\"end_name\", None) custom_mesh_id = data.get(\"mesh_id\", None) force_new_route = data.get(\"force_new_route\", False) tags = data.get(\"tags\", None) if custom_mesh_id: try: logger.info(f\"Got custom mesh id {custom_mesh_id} in request.\") meshes = [Mesh.objects.get(id=custom_mesh_id)] except Mesh.DoesNotExist: msg = f\"Mesh id {custom_mesh_id} requested. Does not exist.\" logger.info(msg) return self.not_found_response(msg) else: meshes = select_mesh(start_lat, start_lon, end_lat, end_lon) if meshes is None: return self.not_found_response(\"No mesh available.\") logger.debug(f\"Using meshes: {[mesh.id for mesh in meshes]}\") # TODO Future: calculate an up to date mesh if none available existing_route = route_exists(meshes, start_lat, start_lon, end_lat, end_lon) if existing_route is not None: if not force_new_route: logger.info(f\"Existing route found: {existing_route}\") # Check if there's an existing job for this route existing_job = existing_route.job_set.latest(\"datetime\") response_data = { \"id\": str(existing_job.id), \"status-url\": reverse( \"job_detail\", args=[existing_job.id], request=request ), \"polarrouteserver-version\": polarrouteserver_version, \"info\": { \"message\": \"Pre-existing route found. Job already exists. To force new calculation, include 'force_new_route': true in POST request.\" }, } return self.accepted_response(response_data) else: logger.info( f\"Found existing route(s) but got force_new_route={force_new_route}, beginning recalculation.\" ) logger.debug( f\"Using mesh {meshes[0].id} as primary mesh with {[mesh.id for mesh in meshes[1:]]} as backup.\" ) # Create route in database route = Route.objects.create( start_lat=start_lat, start_lon=start_lon, end_lat=end_lat, end_lon=end_lon, mesh=meshes[0], start_name=start_name, end_name=end_name, ) # Add tags if provided if tags: # Handle both string and list inputs if isinstance(tags, str): # If it's a string, split by comma and strip whitespace tags_list = [t.strip() for t in tags.split(\",\") if t.strip()] elif isinstance(tags, list): tags_list = [str(t).strip() for t in tags if str(t).strip()] else: tags_list = [] logger.info(f\"Adding tags to route {route.id}: {tags_list}\") if tags_list: route.tags.add(*tags_list) logger.info( f\"Route {route.id} now has tags: {[tag.name for tag in route.tags.all()]}\" ) # Start the task calculation task = optimise_route.delay( route.id, backup_mesh_ids=[mesh.id for mesh in meshes[1:]] ) # Create database record representing the calculation job job = Job.objects.create( id=task.id, route=route, ) # Prepare response data data = { \"id\": job.id, \"status-url\": reverse(\"job_detail\", args=[job.id], request=request), \"polarrouteserver-version\": polarrouteserver_version, } return self.accepted_response(data) post(request) Entry point for route requests Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_route_create_request\", request=inline_serializer( name=\"RouteCreationRequest\", # This should be updated along with the json validation below fields={ \"start_lat\": serializers.FloatField( help_text=\"Starting latitude of the route.\" ), \"start_lon\": serializers.FloatField( help_text=\"Starting longitude of the route.\" ), \"end_lat\": serializers.FloatField( help_text=\"Ending latitude of the route.\" ), \"end_lon\": serializers.FloatField( help_text=\"Ending longitude of the route.\" ), \"start_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the start point.\", ), \"end_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the end point.\" ), \"mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for route calculation.\", ), \"force_new_route\": serializers.BooleanField( required=False, default=False, help_text=\"If true, forces recalculation even if an existing route is found.\", ), \"tags\": serializers.ListField( child=serializers.CharField(max_length=50), required=False, allow_null=True, help_text=\"Optional tags for route (e.g., ['archive', 'SD056']). Can also accept a single string or comma-separated string.\", ), }, ), responses={ 202: routeAcceptedResponseSchema, 400: badRequestResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"\"\"Entry point for route requests\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # TODO validate request JSON try: start_lat = float(data[\"start_lat\"]) start_lon = float(data[\"start_lon\"]) end_lat = float(data[\"end_lat\"]) end_lon = float(data[\"end_lon\"]) except (ValueError, TypeError, KeyError) as e: msg = f\"Invalid coordinate values provided: {e}\" logger.error(msg) return self.bad_request_response(msg) start_name = data.get(\"start_name\", None) end_name = data.get(\"end_name\", None) custom_mesh_id = data.get(\"mesh_id\", None) force_new_route = data.get(\"force_new_route\", False) tags = data.get(\"tags\", None) if custom_mesh_id: try: logger.info(f\"Got custom mesh id {custom_mesh_id} in request.\") meshes = [Mesh.objects.get(id=custom_mesh_id)] except Mesh.DoesNotExist: msg = f\"Mesh id {custom_mesh_id} requested. Does not exist.\" logger.info(msg) return self.not_found_response(msg) else: meshes = select_mesh(start_lat, start_lon, end_lat, end_lon) if meshes is None: return self.not_found_response(\"No mesh available.\") logger.debug(f\"Using meshes: {[mesh.id for mesh in meshes]}\") # TODO Future: calculate an up to date mesh if none available existing_route = route_exists(meshes, start_lat, start_lon, end_lat, end_lon) if existing_route is not None: if not force_new_route: logger.info(f\"Existing route found: {existing_route}\") # Check if there's an existing job for this route existing_job = existing_route.job_set.latest(\"datetime\") response_data = { \"id\": str(existing_job.id), \"status-url\": reverse( \"job_detail\", args=[existing_job.id], request=request ), \"polarrouteserver-version\": polarrouteserver_version, \"info\": { \"message\": \"Pre-existing route found. Job already exists. To force new calculation, include 'force_new_route': true in POST request.\" }, } return self.accepted_response(response_data) else: logger.info( f\"Found existing route(s) but got force_new_route={force_new_route}, beginning recalculation.\" ) logger.debug( f\"Using mesh {meshes[0].id} as primary mesh with {[mesh.id for mesh in meshes[1:]]} as backup.\" ) # Create route in database route = Route.objects.create( start_lat=start_lat, start_lon=start_lon, end_lat=end_lat, end_lon=end_lon, mesh=meshes[0], start_name=start_name, end_name=end_name, ) # Add tags if provided if tags: # Handle both string and list inputs if isinstance(tags, str): # If it's a string, split by comma and strip whitespace tags_list = [t.strip() for t in tags.split(\",\") if t.strip()] elif isinstance(tags, list): tags_list = [str(t).strip() for t in tags if str(t).strip()] else: tags_list = [] logger.info(f\"Adding tags to route {route.id}: {tags_list}\") if tags_list: route.tags.add(*tags_list) logger.info( f\"Route {route.id} now has tags: {[tag.name for tag in route.tags.all()]}\" ) # Start the task calculation task = optimise_route.delay( route.id, backup_mesh_ids=[mesh.id for mesh in meshes[1:]] ) # Create database record representing the calculation job job = Job.objects.create( id=task.id, route=route, ) # Prepare response data data = { \"id\": job.id, \"status-url\": reverse(\"job_detail\", args=[job.id], request=request), \"polarrouteserver-version\": polarrouteserver_version, } return self.accepted_response(data) VehicleDetailView Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class VehicleDetailView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = VehicleSerializer @extend_schema( operation_id=\"api_vehicle_retrieve_by_type\", responses={ 200: successResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, vessel_type): \"\"\"Retrieve vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(f\"Fetching vehicle(s) with vessel_type={vessel_type}\") vehicles = Vehicle.objects.filter(vessel_type=vessel_type) serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data) @extend_schema( operation_id=\"api_vehicle_delete_by_type\", responses={ 204: noContentResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, vessel_type): \"\"\"Delete vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: vehicle = Vehicle.objects.get(vessel_type=vessel_type) vehicle.delete() logger.info(f\"Deleted vehicle with vessel_type={vessel_type}\") return self.no_content_response( data={\"message\": f\"Vehicle '{vessel_type}' deleted successfully.\"} ) except Vehicle.DoesNotExist: logger.error( f\"Vehicle with vessel_type={vessel_type} not found for deletion.\" ) return self.not_found_response( f\"Vehicle with vessel_type '{vessel_type}' not found.\" ) delete(request, vessel_type) Delete vehicle by vessel_type Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_delete_by_type\", responses={ 204: noContentResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, vessel_type): \"\"\"Delete vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: vehicle = Vehicle.objects.get(vessel_type=vessel_type) vehicle.delete() logger.info(f\"Deleted vehicle with vessel_type={vessel_type}\") return self.no_content_response( data={\"message\": f\"Vehicle '{vessel_type}' deleted successfully.\"} ) except Vehicle.DoesNotExist: logger.error( f\"Vehicle with vessel_type={vessel_type} not found for deletion.\" ) return self.not_found_response( f\"Vehicle with vessel_type '{vessel_type}' not found.\" ) get(request, vessel_type) Retrieve vehicle by vessel_type Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_retrieve_by_type\", responses={ 200: successResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, vessel_type): \"\"\"Retrieve vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(f\"Fetching vehicle(s) with vessel_type={vessel_type}\") vehicles = Vehicle.objects.filter(vessel_type=vessel_type) serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data) VehicleRequestView Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class VehicleRequestView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = VehicleSerializer @extend_schema( operation_id=\"api_vehicle_create_request\", request=VehicleSerializer, responses={ 200: successResponseSchema, 400: badRequestResponseSchema, 406: notAcceptableResponseSchema, }, ) def post(self, request): \"\"\"Entry point to create vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # Using Polarroute's built in validation to validate vessel config supplied try: validate_vessel_config(data) logging.info(\"Vessel config is valid.\") except Exception as e: if isinstance(e, ValidationError): error_message = f\"Validation error: {e.message}\" else: error_message = f\"{e}\" logging.error(error_message) return self.bad_request_response(error_message) # Separate out vessel_type and force_properties for checking logic below force_properties = data.get(\"force_properties\", None) vessel_type = data[\"vessel_type\"] # Check if vehicle exists already vehicle_queryset = Vehicle.objects.filter(vessel_type=vessel_type) # If the vehicle exists, obtain it and return an error if user has not specified force_properties if vehicle_queryset.exists(): logger.info(f\"Existing vehicle found: {vessel_type}\") if not force_properties: return self.not_acceptable_response( \"Pre-existing vehicle was found. \" \"To force new properties on an existing vehicle, \" \"include 'force_properties': true in POST request.\" ) # If a user has specified force_properties, update that vessel_type's properties # The vessel_type and force_properties fields need to be removed to allow updating vehicle_properties = data.copy() for key in [\"vessel_type\", \"force_properties\"]: vehicle_properties.pop(key, None) vehicle_queryset.update(**vehicle_properties) logger.info(f\"Updating properties for existing vehicle: {vessel_type}\") response_data = {\"vessel_type\": vessel_type} else: logger.info(\"Creating new vehicle:\") # Create vehicle in database vehicle = Vehicle.objects.create(**data) # Prepare response data response_data = {\"vessel_type\": vehicle.vessel_type} return self.success_response(response_data) @extend_schema( operation_id=\"api_vehicle_list_retrieve\", responses={ 200: successResponseSchema, 204: noContentResponseSchema, }, ) def get(self, request): \"\"\"Retrieve all vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(\"Fetching all vehicles\") vehicles = Vehicle.objects.all() serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data) get(request) Retrieve all vehicles Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_list_retrieve\", responses={ 200: successResponseSchema, 204: noContentResponseSchema, }, ) def get(self, request): \"\"\"Retrieve all vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(\"Fetching all vehicles\") vehicles = Vehicle.objects.all() serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data) post(request) Entry point to create vehicles Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_create_request\", request=VehicleSerializer, responses={ 200: successResponseSchema, 400: badRequestResponseSchema, 406: notAcceptableResponseSchema, }, ) def post(self, request): \"\"\"Entry point to create vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # Using Polarroute's built in validation to validate vessel config supplied try: validate_vessel_config(data) logging.info(\"Vessel config is valid.\") except Exception as e: if isinstance(e, ValidationError): error_message = f\"Validation error: {e.message}\" else: error_message = f\"{e}\" logging.error(error_message) return self.bad_request_response(error_message) # Separate out vessel_type and force_properties for checking logic below force_properties = data.get(\"force_properties\", None) vessel_type = data[\"vessel_type\"] # Check if vehicle exists already vehicle_queryset = Vehicle.objects.filter(vessel_type=vessel_type) # If the vehicle exists, obtain it and return an error if user has not specified force_properties if vehicle_queryset.exists(): logger.info(f\"Existing vehicle found: {vessel_type}\") if not force_properties: return self.not_acceptable_response( \"Pre-existing vehicle was found. \" \"To force new properties on an existing vehicle, \" \"include 'force_properties': true in POST request.\" ) # If a user has specified force_properties, update that vessel_type's properties # The vessel_type and force_properties fields need to be removed to allow updating vehicle_properties = data.copy() for key in [\"vessel_type\", \"force_properties\"]: vehicle_properties.pop(key, None) vehicle_queryset.update(**vehicle_properties) logger.info(f\"Updating properties for existing vehicle: {vessel_type}\") response_data = {\"vessel_type\": vessel_type} else: logger.info(\"Creating new vehicle:\") # Create vehicle in database vehicle = Vehicle.objects.create(**data) # Prepare response data response_data = {\"vessel_type\": vehicle.vessel_type} return self.success_response(response_data) VehicleTypeListView Bases: LoggingMixin , ResponseMixin , GenericAPIView Endpoint to list all distinct vessel_types available. Source code in polarrouteserver/route_api/views.py class VehicleTypeListView(LoggingMixin, ResponseMixin, GenericAPIView): \"\"\" Endpoint to list all distinct vessel_types available. \"\"\" serializer_class = VesselTypeSerializer @extend_schema( operation_id=\"api_vehicle_available_list\", responses={ 200: vehicleTypeListResponseSchema, }, ) def get(self, request): logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) vessel_types = Vehicle.objects.values_list(\"vessel_type\", flat=True).distinct() vessel_types_list = list(vessel_types) if not vessel_types_list: logger.warning(\"No available vessel_types found in the database.\") return self.success_response( {\"vessel_types\": [], \"message\": \"No available vessel types found.\"} ) logger.info(f\"Returning {len(vessel_types_list)} distinct vessel_types\") return self.success_response({\"vessel_types\": vessel_types_list})","title":"views"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.EvaluateRouteView","text":"Bases: LoggingMixin , ResponseMixin , APIView Source code in polarrouteserver/route_api/views.py class EvaluateRouteView(LoggingMixin, ResponseMixin, APIView): serializer_class = None @extend_schema( operation_id=\"api_route_evaluation\", request=inline_serializer( name=\"RouteEvaluationRequest\", fields={ \"route\": serializers.JSONField(help_text=\"The route JSON to evaluate.\"), \"custom_mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for evaluation.\", ), }, ), responses={ 200: routeEvaluationResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"POST Endpoint to evaluate traveltime and fuel usage on a given route.\" data = request.data route_json = data.get(\"route\", None) custom_mesh_id = data.get(\"custom_mesh_id\", None) if custom_mesh_id: try: mesh = Mesh.objects.get(id=custom_mesh_id) meshes = [mesh] except Mesh.DoesNotExist: return self.not_found_response(\"No mesh available.\") else: meshes = select_mesh_for_route_evaluation(route_json) if meshes is None: return self.not_found_response(\"No mesh available.\") response_data = {\"polarrouteserver-version\": polarrouteserver_version} result_dict = evaluate_route(route_json, meshes[0]) if result_dict is None: result_dict = {\"error\": \"Route evaluation not possible.\"} response_data.update(result_dict) return self.success_response(response_data)","title":"EvaluateRouteView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.EvaluateRouteView.post","text":"POST Endpoint to evaluate traveltime and fuel usage on a given route. Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_route_evaluation\", request=inline_serializer( name=\"RouteEvaluationRequest\", fields={ \"route\": serializers.JSONField(help_text=\"The route JSON to evaluate.\"), \"custom_mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for evaluation.\", ), }, ), responses={ 200: routeEvaluationResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"POST Endpoint to evaluate traveltime and fuel usage on a given route.\" data = request.data route_json = data.get(\"route\", None) custom_mesh_id = data.get(\"custom_mesh_id\", None) if custom_mesh_id: try: mesh = Mesh.objects.get(id=custom_mesh_id) meshes = [mesh] except Mesh.DoesNotExist: return self.not_found_response(\"No mesh available.\") else: meshes = select_mesh_for_route_evaluation(route_json) if meshes is None: return self.not_found_response(\"No mesh available.\") response_data = {\"polarrouteserver-version\": polarrouteserver_version} result_dict = evaluate_route(route_json, meshes[0]) if result_dict is None: result_dict = {\"error\": \"Route evaluation not possible.\"} response_data.update(result_dict) return self.success_response(response_data)","title":"post"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.JobView","text":"Bases: LoggingMixin , ResponseMixin , GenericAPIView View for handling job status requests Source code in polarrouteserver/route_api/views.py class JobView(LoggingMixin, ResponseMixin, GenericAPIView): \"\"\" View for handling job status requests \"\"\" serializer_class = JobStatusSerializer @extend_schema( operation_id=\"api_job_retrieve_status\", responses={ 200: jobStatusResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return status of job and route URL if complete.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") serializer = JobStatusSerializer(job, context={\"request\": request}) return self.success_response(serializer.data) @extend_schema( operation_id=\"api_job_cancel\", responses={ 202: acceptedResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, id): \"\"\"Cancel job\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") # Store route ID for response before deletion route_id = job.route.id # Cancel the Celery task result = AsyncResult(id=str(id), app=app) result.revoke() # Delete the corresponding route (this will also delete the job due to CASCADE) job.route.delete() return self.accepted_response( { \"message\": f\"Job {id} cancellation requested and route {route_id} deleted.\", \"job_id\": str(job.id), \"route_id\": route_id, } )","title":"JobView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.JobView.delete","text":"Cancel job Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_job_cancel\", responses={ 202: acceptedResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, id): \"\"\"Cancel job\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") # Store route ID for response before deletion route_id = job.route.id # Cancel the Celery task result = AsyncResult(id=str(id), app=app) result.revoke() # Delete the corresponding route (this will also delete the job due to CASCADE) job.route.delete() return self.accepted_response( { \"message\": f\"Job {id} cancellation requested and route {route_id} deleted.\", \"job_id\": str(job.id), \"route_id\": route_id, } )","title":"delete"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.JobView.get","text":"Return status of job and route URL if complete. Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_job_retrieve_status\", responses={ 200: jobStatusResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return status of job and route URL if complete.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: job = Job.objects.get(id=id) except Job.DoesNotExist: return self.not_found_response(f\"Job with id {id} not found.\") serializer = JobStatusSerializer(job, context={\"request\": request}) return self.success_response(serializer.data)","title":"get"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.LoggingMixin","text":"Provides full logging of requests and responses Source code in polarrouteserver/route_api/views.py class LoggingMixin: \"\"\" Provides full logging of requests and responses \"\"\" def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) self.logger = logging.getLogger(\"django.request\") def initial(self, request, *args, **kwargs): try: self.logger.debug( { \"request\": request.data, \"method\": request.method, \"endpoint\": request.path, \"user\": request.user.username, \"ip_address\": request.META.get(\"REMOTE_ADDR\"), \"user_agent\": request.META.get(\"HTTP_USER_AGENT\"), } ) except Exception: self.logger.exception(\"Error logging request data\") super().initial(request, *args, **kwargs) def finalize_response(self, request, response, *args, **kwargs): try: self.logger.debug( { \"response\": response.data, \"status_code\": response.status_code, \"user\": request.user.username, \"ip_address\": request.META.get(\"REMOTE_ADDR\"), \"user_agent\": request.META.get(\"HTTP_USER_AGENT\"), } ) except Exception: self.logger.exception(\"Error logging response data\") return super().finalize_response(request, response, *args, **kwargs)","title":"LoggingMixin"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.MeshView","text":"Bases: LoggingMixin , ResponseMixin , APIView Source code in polarrouteserver/route_api/views.py class MeshView(LoggingMixin, ResponseMixin, APIView): serializer_class = None @extend_schema( operation_id=\"api_mesh_get\", responses={ 200: meshDetailResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"GET Meshes by id\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) data = {\"polarrouteserver-version\": polarrouteserver_version} try: mesh = Mesh.objects.get(id=id) data.update( dict( id=mesh.id, json=mesh.json, geojson=EnvironmentMesh.load_from_json(mesh.json).to_geojson(), ) ) return self.success_response(data) except Mesh.DoesNotExist: return self.not_found_response(f\"Mesh with id {id} not found.\")","title":"MeshView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.MeshView.get","text":"GET Meshes by id Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_mesh_get\", responses={ 200: meshDetailResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"GET Meshes by id\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) data = {\"polarrouteserver-version\": polarrouteserver_version} try: mesh = Mesh.objects.get(id=id) data.update( dict( id=mesh.id, json=mesh.json, geojson=EnvironmentMesh.load_from_json(mesh.json).to_geojson(), ) ) return self.success_response(data) except Mesh.DoesNotExist: return self.not_found_response(f\"Mesh with id {id} not found.\")","title":"get"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.RecentRoutesView","text":"Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class RecentRoutesView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = None # No serializer needed - using manual response building def _get_celery_task_status(self, job_id, calculated_timestamp, route_info): \"\"\" Get Celery task status. Uses database state to avoid Celery broker calls. \"\"\" if calculated_timestamp: return \"SUCCESS\" if route_info and \"error\" in str(route_info).lower(): return \"FAILURE\" # Handle missing job scenarios if not job_id: return \"PENDING\" # Job exists but no calculation yet - also PENDING return \"PENDING\" @extend_schema( operation_id=\"api_recent_routes_list\", responses={ 200: recentRoutesResponseSchema, }, ) def get(self, request): \"\"\"Get recent routes\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) # Only get today's routes routes_recent = ( Route.objects.filter(requested__gte=timezone.now() - timedelta(hours=24)) .select_related(\"job\") .values( \"id\", \"start_lat\", \"start_lon\", \"end_lat\", \"end_lon\", \"start_name\", \"end_name\", \"polar_route_version\", \"requested\", \"calculated\", \"info\", \"mesh_id\", \"mesh__name\", \"job__id\", ) .order_by(\"-requested\") ) if not routes_recent: return self.success_response( { \"routes\": [], \"polarrouteserver-version\": polarrouteserver_version, \"message\": \"No recent routes found for last 24 hours.\", } ) # Get route IDs for tag lookup route_ids = [route[\"id\"] for route in routes_recent] # Get all tags for routes in one query route_tags = {} if route_ids: content_type = ContentType.objects.get_for_model(Route) tagged_items = ( TaggedItem.objects.filter( content_type=content_type, object_id__in=route_ids ) .select_related(\"tag\") .values(\"object_id\", \"tag__name\") ) for item in tagged_items: route_id = int(item[\"object_id\"]) if route_id not in route_tags: route_tags[route_id] = [] route_tags[route_id].append(item[\"tag__name\"]) routes_data = [] for route in routes_recent: job_id = route.get(\"job__id\") status = self._get_celery_task_status( job_id, route[\"calculated\"], route[\"info\"] ) # Build lightweight route data route_data = { \"id\": route[\"id\"], \"start_lat\": route[\"start_lat\"], \"start_lon\": route[\"start_lon\"], \"end_lat\": route[\"end_lat\"], \"end_lon\": route[\"end_lon\"], \"start_name\": route[\"start_name\"], \"end_name\": route[\"end_name\"], \"polar_route_version\": route[\"polar_route_version\"], \"requested\": route[\"requested\"].isoformat() if route[\"requested\"] else None, \"calculated\": route[\"calculated\"].isoformat() if route[\"calculated\"] else None, \"status\": status, \"route_url\": reverse( \"route_detail\", args=[route[\"id\"]], request=request ), \"tags\": route_tags.get(route[\"id\"], []), } if job_id: route_data[\"job_id\"] = job_id route_data[\"job_status_url\"] = reverse( \"job_detail\", args=[job_id], request=request ) # Add minimal mesh info without loading the heavy JSON if route[\"mesh_id\"]: route_data[\"mesh\"] = { \"id\": route[\"mesh_id\"], \"name\": route[\"mesh__name\"], } routes_data.append(route_data) response_data = { \"routes\": routes_data, \"polarrouteserver-version\": polarrouteserver_version, } return self.success_response(response_data)","title":"RecentRoutesView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.RecentRoutesView.get","text":"Get recent routes Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_recent_routes_list\", responses={ 200: recentRoutesResponseSchema, }, ) def get(self, request): \"\"\"Get recent routes\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) # Only get today's routes routes_recent = ( Route.objects.filter(requested__gte=timezone.now() - timedelta(hours=24)) .select_related(\"job\") .values( \"id\", \"start_lat\", \"start_lon\", \"end_lat\", \"end_lon\", \"start_name\", \"end_name\", \"polar_route_version\", \"requested\", \"calculated\", \"info\", \"mesh_id\", \"mesh__name\", \"job__id\", ) .order_by(\"-requested\") ) if not routes_recent: return self.success_response( { \"routes\": [], \"polarrouteserver-version\": polarrouteserver_version, \"message\": \"No recent routes found for last 24 hours.\", } ) # Get route IDs for tag lookup route_ids = [route[\"id\"] for route in routes_recent] # Get all tags for routes in one query route_tags = {} if route_ids: content_type = ContentType.objects.get_for_model(Route) tagged_items = ( TaggedItem.objects.filter( content_type=content_type, object_id__in=route_ids ) .select_related(\"tag\") .values(\"object_id\", \"tag__name\") ) for item in tagged_items: route_id = int(item[\"object_id\"]) if route_id not in route_tags: route_tags[route_id] = [] route_tags[route_id].append(item[\"tag__name\"]) routes_data = [] for route in routes_recent: job_id = route.get(\"job__id\") status = self._get_celery_task_status( job_id, route[\"calculated\"], route[\"info\"] ) # Build lightweight route data route_data = { \"id\": route[\"id\"], \"start_lat\": route[\"start_lat\"], \"start_lon\": route[\"start_lon\"], \"end_lat\": route[\"end_lat\"], \"end_lon\": route[\"end_lon\"], \"start_name\": route[\"start_name\"], \"end_name\": route[\"end_name\"], \"polar_route_version\": route[\"polar_route_version\"], \"requested\": route[\"requested\"].isoformat() if route[\"requested\"] else None, \"calculated\": route[\"calculated\"].isoformat() if route[\"calculated\"] else None, \"status\": status, \"route_url\": reverse( \"route_detail\", args=[route[\"id\"]], request=request ), \"tags\": route_tags.get(route[\"id\"], []), } if job_id: route_data[\"job_id\"] = job_id route_data[\"job_status_url\"] = reverse( \"job_detail\", args=[job_id], request=request ) # Add minimal mesh info without loading the heavy JSON if route[\"mesh_id\"]: route_data[\"mesh\"] = { \"id\": route[\"mesh_id\"], \"name\": route[\"mesh__name\"], } routes_data.append(route_data) response_data = { \"routes\": routes_data, \"polarrouteserver-version\": polarrouteserver_version, } return self.success_response(response_data)","title":"get"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.RouteDetailView","text":"Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class RouteDetailView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = RouteSerializer @extend_schema( operation_id=\"api_route_retrieve_by_id\", description=\"Retrieve route details by ID. Returns the route data.\", responses={ 200: routeSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return route data by route ID.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: route = Route.objects.get(id=id) except Route.DoesNotExist: return self.not_found_response(f\"Route with id {id} not found.\") data = RouteSerializer(route).data return self.success_response(data)","title":"RouteDetailView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.RouteDetailView.get","text":"Return route data by route ID. Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_route_retrieve_by_id\", description=\"Retrieve route details by ID. Returns the route data.\", responses={ 200: routeSchema, 404: notFoundResponseSchema, }, ) def get(self, request, id): \"\"\"Return route data by route ID.\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: route = Route.objects.get(id=id) except Route.DoesNotExist: return self.not_found_response(f\"Route with id {id} not found.\") data = RouteSerializer(route).data return self.success_response(data)","title":"get"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.RouteRequestView","text":"Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class RouteRequestView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = RouteSerializer @extend_schema( operation_id=\"api_route_create_request\", request=inline_serializer( name=\"RouteCreationRequest\", # This should be updated along with the json validation below fields={ \"start_lat\": serializers.FloatField( help_text=\"Starting latitude of the route.\" ), \"start_lon\": serializers.FloatField( help_text=\"Starting longitude of the route.\" ), \"end_lat\": serializers.FloatField( help_text=\"Ending latitude of the route.\" ), \"end_lon\": serializers.FloatField( help_text=\"Ending longitude of the route.\" ), \"start_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the start point.\", ), \"end_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the end point.\" ), \"mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for route calculation.\", ), \"force_new_route\": serializers.BooleanField( required=False, default=False, help_text=\"If true, forces recalculation even if an existing route is found.\", ), \"tags\": serializers.ListField( child=serializers.CharField(max_length=50), required=False, allow_null=True, help_text=\"Optional tags for route (e.g., ['archive', 'SD056']). Can also accept a single string or comma-separated string.\", ), }, ), responses={ 202: routeAcceptedResponseSchema, 400: badRequestResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"\"\"Entry point for route requests\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # TODO validate request JSON try: start_lat = float(data[\"start_lat\"]) start_lon = float(data[\"start_lon\"]) end_lat = float(data[\"end_lat\"]) end_lon = float(data[\"end_lon\"]) except (ValueError, TypeError, KeyError) as e: msg = f\"Invalid coordinate values provided: {e}\" logger.error(msg) return self.bad_request_response(msg) start_name = data.get(\"start_name\", None) end_name = data.get(\"end_name\", None) custom_mesh_id = data.get(\"mesh_id\", None) force_new_route = data.get(\"force_new_route\", False) tags = data.get(\"tags\", None) if custom_mesh_id: try: logger.info(f\"Got custom mesh id {custom_mesh_id} in request.\") meshes = [Mesh.objects.get(id=custom_mesh_id)] except Mesh.DoesNotExist: msg = f\"Mesh id {custom_mesh_id} requested. Does not exist.\" logger.info(msg) return self.not_found_response(msg) else: meshes = select_mesh(start_lat, start_lon, end_lat, end_lon) if meshes is None: return self.not_found_response(\"No mesh available.\") logger.debug(f\"Using meshes: {[mesh.id for mesh in meshes]}\") # TODO Future: calculate an up to date mesh if none available existing_route = route_exists(meshes, start_lat, start_lon, end_lat, end_lon) if existing_route is not None: if not force_new_route: logger.info(f\"Existing route found: {existing_route}\") # Check if there's an existing job for this route existing_job = existing_route.job_set.latest(\"datetime\") response_data = { \"id\": str(existing_job.id), \"status-url\": reverse( \"job_detail\", args=[existing_job.id], request=request ), \"polarrouteserver-version\": polarrouteserver_version, \"info\": { \"message\": \"Pre-existing route found. Job already exists. To force new calculation, include 'force_new_route': true in POST request.\" }, } return self.accepted_response(response_data) else: logger.info( f\"Found existing route(s) but got force_new_route={force_new_route}, beginning recalculation.\" ) logger.debug( f\"Using mesh {meshes[0].id} as primary mesh with {[mesh.id for mesh in meshes[1:]]} as backup.\" ) # Create route in database route = Route.objects.create( start_lat=start_lat, start_lon=start_lon, end_lat=end_lat, end_lon=end_lon, mesh=meshes[0], start_name=start_name, end_name=end_name, ) # Add tags if provided if tags: # Handle both string and list inputs if isinstance(tags, str): # If it's a string, split by comma and strip whitespace tags_list = [t.strip() for t in tags.split(\",\") if t.strip()] elif isinstance(tags, list): tags_list = [str(t).strip() for t in tags if str(t).strip()] else: tags_list = [] logger.info(f\"Adding tags to route {route.id}: {tags_list}\") if tags_list: route.tags.add(*tags_list) logger.info( f\"Route {route.id} now has tags: {[tag.name for tag in route.tags.all()]}\" ) # Start the task calculation task = optimise_route.delay( route.id, backup_mesh_ids=[mesh.id for mesh in meshes[1:]] ) # Create database record representing the calculation job job = Job.objects.create( id=task.id, route=route, ) # Prepare response data data = { \"id\": job.id, \"status-url\": reverse(\"job_detail\", args=[job.id], request=request), \"polarrouteserver-version\": polarrouteserver_version, } return self.accepted_response(data)","title":"RouteRequestView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.RouteRequestView.post","text":"Entry point for route requests Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_route_create_request\", request=inline_serializer( name=\"RouteCreationRequest\", # This should be updated along with the json validation below fields={ \"start_lat\": serializers.FloatField( help_text=\"Starting latitude of the route.\" ), \"start_lon\": serializers.FloatField( help_text=\"Starting longitude of the route.\" ), \"end_lat\": serializers.FloatField( help_text=\"Ending latitude of the route.\" ), \"end_lon\": serializers.FloatField( help_text=\"Ending longitude of the route.\" ), \"start_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the start point.\", ), \"end_name\": serializers.CharField( required=False, allow_null=True, help_text=\"Name of the end point.\" ), \"mesh_id\": serializers.IntegerField( required=False, allow_null=True, help_text=\"Optional: Custom mesh ID to use for route calculation.\", ), \"force_new_route\": serializers.BooleanField( required=False, default=False, help_text=\"If true, forces recalculation even if an existing route is found.\", ), \"tags\": serializers.ListField( child=serializers.CharField(max_length=50), required=False, allow_null=True, help_text=\"Optional tags for route (e.g., ['archive', 'SD056']). Can also accept a single string or comma-separated string.\", ), }, ), responses={ 202: routeAcceptedResponseSchema, 400: badRequestResponseSchema, 404: notFoundResponseSchema, }, ) def post(self, request): \"\"\"Entry point for route requests\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # TODO validate request JSON try: start_lat = float(data[\"start_lat\"]) start_lon = float(data[\"start_lon\"]) end_lat = float(data[\"end_lat\"]) end_lon = float(data[\"end_lon\"]) except (ValueError, TypeError, KeyError) as e: msg = f\"Invalid coordinate values provided: {e}\" logger.error(msg) return self.bad_request_response(msg) start_name = data.get(\"start_name\", None) end_name = data.get(\"end_name\", None) custom_mesh_id = data.get(\"mesh_id\", None) force_new_route = data.get(\"force_new_route\", False) tags = data.get(\"tags\", None) if custom_mesh_id: try: logger.info(f\"Got custom mesh id {custom_mesh_id} in request.\") meshes = [Mesh.objects.get(id=custom_mesh_id)] except Mesh.DoesNotExist: msg = f\"Mesh id {custom_mesh_id} requested. Does not exist.\" logger.info(msg) return self.not_found_response(msg) else: meshes = select_mesh(start_lat, start_lon, end_lat, end_lon) if meshes is None: return self.not_found_response(\"No mesh available.\") logger.debug(f\"Using meshes: {[mesh.id for mesh in meshes]}\") # TODO Future: calculate an up to date mesh if none available existing_route = route_exists(meshes, start_lat, start_lon, end_lat, end_lon) if existing_route is not None: if not force_new_route: logger.info(f\"Existing route found: {existing_route}\") # Check if there's an existing job for this route existing_job = existing_route.job_set.latest(\"datetime\") response_data = { \"id\": str(existing_job.id), \"status-url\": reverse( \"job_detail\", args=[existing_job.id], request=request ), \"polarrouteserver-version\": polarrouteserver_version, \"info\": { \"message\": \"Pre-existing route found. Job already exists. To force new calculation, include 'force_new_route': true in POST request.\" }, } return self.accepted_response(response_data) else: logger.info( f\"Found existing route(s) but got force_new_route={force_new_route}, beginning recalculation.\" ) logger.debug( f\"Using mesh {meshes[0].id} as primary mesh with {[mesh.id for mesh in meshes[1:]]} as backup.\" ) # Create route in database route = Route.objects.create( start_lat=start_lat, start_lon=start_lon, end_lat=end_lat, end_lon=end_lon, mesh=meshes[0], start_name=start_name, end_name=end_name, ) # Add tags if provided if tags: # Handle both string and list inputs if isinstance(tags, str): # If it's a string, split by comma and strip whitespace tags_list = [t.strip() for t in tags.split(\",\") if t.strip()] elif isinstance(tags, list): tags_list = [str(t).strip() for t in tags if str(t).strip()] else: tags_list = [] logger.info(f\"Adding tags to route {route.id}: {tags_list}\") if tags_list: route.tags.add(*tags_list) logger.info( f\"Route {route.id} now has tags: {[tag.name for tag in route.tags.all()]}\" ) # Start the task calculation task = optimise_route.delay( route.id, backup_mesh_ids=[mesh.id for mesh in meshes[1:]] ) # Create database record representing the calculation job job = Job.objects.create( id=task.id, route=route, ) # Prepare response data data = { \"id\": job.id, \"status-url\": reverse(\"job_detail\", args=[job.id], request=request), \"polarrouteserver-version\": polarrouteserver_version, } return self.accepted_response(data)","title":"post"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.VehicleDetailView","text":"Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class VehicleDetailView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = VehicleSerializer @extend_schema( operation_id=\"api_vehicle_retrieve_by_type\", responses={ 200: successResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, vessel_type): \"\"\"Retrieve vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(f\"Fetching vehicle(s) with vessel_type={vessel_type}\") vehicles = Vehicle.objects.filter(vessel_type=vessel_type) serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data) @extend_schema( operation_id=\"api_vehicle_delete_by_type\", responses={ 204: noContentResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, vessel_type): \"\"\"Delete vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: vehicle = Vehicle.objects.get(vessel_type=vessel_type) vehicle.delete() logger.info(f\"Deleted vehicle with vessel_type={vessel_type}\") return self.no_content_response( data={\"message\": f\"Vehicle '{vessel_type}' deleted successfully.\"} ) except Vehicle.DoesNotExist: logger.error( f\"Vehicle with vessel_type={vessel_type} not found for deletion.\" ) return self.not_found_response( f\"Vehicle with vessel_type '{vessel_type}' not found.\" )","title":"VehicleDetailView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.VehicleDetailView.delete","text":"Delete vehicle by vessel_type Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_delete_by_type\", responses={ 204: noContentResponseSchema, 404: notFoundResponseSchema, }, ) def delete(self, request, vessel_type): \"\"\"Delete vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) try: vehicle = Vehicle.objects.get(vessel_type=vessel_type) vehicle.delete() logger.info(f\"Deleted vehicle with vessel_type={vessel_type}\") return self.no_content_response( data={\"message\": f\"Vehicle '{vessel_type}' deleted successfully.\"} ) except Vehicle.DoesNotExist: logger.error( f\"Vehicle with vessel_type={vessel_type} not found for deletion.\" ) return self.not_found_response( f\"Vehicle with vessel_type '{vessel_type}' not found.\" )","title":"delete"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.VehicleDetailView.get","text":"Retrieve vehicle by vessel_type Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_retrieve_by_type\", responses={ 200: successResponseSchema, 404: notFoundResponseSchema, }, ) def get(self, request, vessel_type): \"\"\"Retrieve vehicle by vessel_type\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(f\"Fetching vehicle(s) with vessel_type={vessel_type}\") vehicles = Vehicle.objects.filter(vessel_type=vessel_type) serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data)","title":"get"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.VehicleRequestView","text":"Bases: LoggingMixin , ResponseMixin , GenericAPIView Source code in polarrouteserver/route_api/views.py class VehicleRequestView(LoggingMixin, ResponseMixin, GenericAPIView): serializer_class = VehicleSerializer @extend_schema( operation_id=\"api_vehicle_create_request\", request=VehicleSerializer, responses={ 200: successResponseSchema, 400: badRequestResponseSchema, 406: notAcceptableResponseSchema, }, ) def post(self, request): \"\"\"Entry point to create vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # Using Polarroute's built in validation to validate vessel config supplied try: validate_vessel_config(data) logging.info(\"Vessel config is valid.\") except Exception as e: if isinstance(e, ValidationError): error_message = f\"Validation error: {e.message}\" else: error_message = f\"{e}\" logging.error(error_message) return self.bad_request_response(error_message) # Separate out vessel_type and force_properties for checking logic below force_properties = data.get(\"force_properties\", None) vessel_type = data[\"vessel_type\"] # Check if vehicle exists already vehicle_queryset = Vehicle.objects.filter(vessel_type=vessel_type) # If the vehicle exists, obtain it and return an error if user has not specified force_properties if vehicle_queryset.exists(): logger.info(f\"Existing vehicle found: {vessel_type}\") if not force_properties: return self.not_acceptable_response( \"Pre-existing vehicle was found. \" \"To force new properties on an existing vehicle, \" \"include 'force_properties': true in POST request.\" ) # If a user has specified force_properties, update that vessel_type's properties # The vessel_type and force_properties fields need to be removed to allow updating vehicle_properties = data.copy() for key in [\"vessel_type\", \"force_properties\"]: vehicle_properties.pop(key, None) vehicle_queryset.update(**vehicle_properties) logger.info(f\"Updating properties for existing vehicle: {vessel_type}\") response_data = {\"vessel_type\": vessel_type} else: logger.info(\"Creating new vehicle:\") # Create vehicle in database vehicle = Vehicle.objects.create(**data) # Prepare response data response_data = {\"vessel_type\": vehicle.vessel_type} return self.success_response(response_data) @extend_schema( operation_id=\"api_vehicle_list_retrieve\", responses={ 200: successResponseSchema, 204: noContentResponseSchema, }, ) def get(self, request): \"\"\"Retrieve all vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(\"Fetching all vehicles\") vehicles = Vehicle.objects.all() serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data)","title":"VehicleRequestView"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.VehicleRequestView.get","text":"Retrieve all vehicles Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_list_retrieve\", responses={ 200: successResponseSchema, 204: noContentResponseSchema, }, ) def get(self, request): \"\"\"Retrieve all vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) logger.info(\"Fetching all vehicles\") vehicles = Vehicle.objects.all() serializer = self.serializer_class(vehicles, many=True) return self.success_response(serializer.data)","title":"get"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.VehicleRequestView.post","text":"Entry point to create vehicles Source code in polarrouteserver/route_api/views.py @extend_schema( operation_id=\"api_vehicle_create_request\", request=VehicleSerializer, responses={ 200: successResponseSchema, 400: badRequestResponseSchema, 406: notAcceptableResponseSchema, }, ) def post(self, request): \"\"\"Entry point to create vehicles\"\"\" logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}: {request.data}\" ) data = request.data # Using Polarroute's built in validation to validate vessel config supplied try: validate_vessel_config(data) logging.info(\"Vessel config is valid.\") except Exception as e: if isinstance(e, ValidationError): error_message = f\"Validation error: {e.message}\" else: error_message = f\"{e}\" logging.error(error_message) return self.bad_request_response(error_message) # Separate out vessel_type and force_properties for checking logic below force_properties = data.get(\"force_properties\", None) vessel_type = data[\"vessel_type\"] # Check if vehicle exists already vehicle_queryset = Vehicle.objects.filter(vessel_type=vessel_type) # If the vehicle exists, obtain it and return an error if user has not specified force_properties if vehicle_queryset.exists(): logger.info(f\"Existing vehicle found: {vessel_type}\") if not force_properties: return self.not_acceptable_response( \"Pre-existing vehicle was found. \" \"To force new properties on an existing vehicle, \" \"include 'force_properties': true in POST request.\" ) # If a user has specified force_properties, update that vessel_type's properties # The vessel_type and force_properties fields need to be removed to allow updating vehicle_properties = data.copy() for key in [\"vessel_type\", \"force_properties\"]: vehicle_properties.pop(key, None) vehicle_queryset.update(**vehicle_properties) logger.info(f\"Updating properties for existing vehicle: {vessel_type}\") response_data = {\"vessel_type\": vessel_type} else: logger.info(\"Creating new vehicle:\") # Create vehicle in database vehicle = Vehicle.objects.create(**data) # Prepare response data response_data = {\"vessel_type\": vehicle.vessel_type} return self.success_response(response_data)","title":"post"},{"location":"autoapi/polarrouteserver/route_api/views/#polarrouteserver.route_api.views.VehicleTypeListView","text":"Bases: LoggingMixin , ResponseMixin , GenericAPIView Endpoint to list all distinct vessel_types available. Source code in polarrouteserver/route_api/views.py class VehicleTypeListView(LoggingMixin, ResponseMixin, GenericAPIView): \"\"\" Endpoint to list all distinct vessel_types available. \"\"\" serializer_class = VesselTypeSerializer @extend_schema( operation_id=\"api_vehicle_available_list\", responses={ 200: vehicleTypeListResponseSchema, }, ) def get(self, request): logger.info( f\"{request.method} {request.path} from {request.META.get('REMOTE_ADDR')}\" ) vessel_types = Vehicle.objects.values_list(\"vessel_type\", flat=True).distinct() vessel_types_list = list(vessel_types) if not vessel_types_list: logger.warning(\"No available vessel_types found in the database.\") return self.success_response( {\"vessel_types\": [], \"message\": \"No available vessel types found.\"} ) logger.info(f\"Returning {len(vessel_types_list)} distinct vessel_types\") return self.success_response({\"vessel_types\": vessel_types_list})","title":"VehicleTypeListView"},{"location":"autoapi/polarrouteserver/utils/","text":"","title":"utils"},{"location":"autoapi/polarrouteserver/utils/loggers/","text":"GroupWriteRotatingFileHandler Bases: RotatingFileHandler A rotating file handler which allows group write permissions. Source code in polarrouteserver/utils/loggers.py class GroupWriteRotatingFileHandler(logging.handlers.RotatingFileHandler): \"\"\"A rotating file handler which allows group write permissions.\"\"\" def _open(self): # Open the file using the standard method stream = super()._open() # Explicitly change permissions to 664 (rw-rw-r--) # 0o664 is the octal representation try: os.chmod(self.baseFilename, 0o664) except OSError: # Handle cases where the process isn't the owner (rare in proper setups) pass return stream","title":"loggers"},{"location":"autoapi/polarrouteserver/utils/loggers/#polarrouteserver.utils.loggers.GroupWriteRotatingFileHandler","text":"Bases: RotatingFileHandler A rotating file handler which allows group write permissions. Source code in polarrouteserver/utils/loggers.py class GroupWriteRotatingFileHandler(logging.handlers.RotatingFileHandler): \"\"\"A rotating file handler which allows group write permissions.\"\"\" def _open(self): # Open the file using the standard method stream = super()._open() # Explicitly change permissions to 664 (rw-rw-r--) # 0o664 is the octal representation try: os.chmod(self.baseFilename, 0o664) except OSError: # Handle cases where the process isn't the owner (rare in proper setups) pass return stream","title":"GroupWriteRotatingFileHandler"},{"location":"autoapi/request_route/","text":"","title":"request_route"},{"location":"autoapi/request_route/request_route/","text":"Demo script for requesting routes from PolarRouteServer API using Python standard library. This script demonstrates the two-step workflow: 1. Submit a route request to /api/route, which returns a job ID 2. Monitor job status at /api/job/{job_id} until completion 3. When job is complete, retrieve route data from /api/route/{route_id} make_request(type, url, endpoint, headers, body=None) Sends HTTP request, prints details and returns response. Parameters: type ( str ) \u2013 HTTP request type, e.g. \"GET\" or \"POST\" url ( str ) \u2013 base url to send request to endpoint ( str ) \u2013 endpoint, e.g. \"/api/route/some-id\" headers ( dict ) \u2013 HTTP headers body ( dict , default: None ) \u2013 HTTP request body. Defaults to None. Returns: HTTPResponse \u2013 http.client.HTTPResponse HTTPResponse \u2013 status Source code in request_route/request_route.py def make_request( type: str, url: str, endpoint: str, headers: dict, body: dict = None ) -> http.client.HTTPResponse: \"\"\"Sends HTTP request, prints details and returns response. Args: type (str): HTTP request type, e.g. \"GET\" or \"POST\" url (str): base url to send request to endpoint (str): endpoint, e.g. \"/api/route/some-id\" headers (dict): HTTP headers body (dict, optional): HTTP request body. Defaults to None. Returns: http.client.HTTPResponse status \"\"\" sending_str = f\"Sending {type} request to {url}{endpoint}: \\nHeaders: {headers}\\n\" if body: sending_str += f\"Body: {body}\\n\" print(sending_str) request_url = url + endpoint if endpoint else url req = request.Request(request_url, data=body, headers=headers) unverified_context = ssl._create_unverified_context() try: response = request.urlopen(req, context=unverified_context) except HTTPError as err: print(f\"A HTTPError was thrown: {err.code} {err.reason}\") print( \"One possibility is that there is no mesh available.\" ) # this is a quick and dirty workaround since urllib throws errors on 404, even though this is a valid use of a that error code return None, err.status print(f\"Response: {response.status} {response.reason}\") return json.loads(response.read()), response.status parse_location(location) Parameters: location ( str ) \u2013 a location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 Returns: Location \u2013 a Location object Source code in request_route/request_route.py def parse_location(location: str) -> Location: \"\"\" Args: location (str): a location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 Returns: a Location object \"\"\" pattern = r\"[+-]?([0-9]*[.])?[0-9]+,[+-]?([0-9]*[.])?[0-9]+\" if location in STANDARD_LOCATIONS.keys(): standard_location = STANDARD_LOCATIONS.get(location) return standard_location elif re.search(pattern, location): coords = re.search(pattern, location).group().split(\",\") return Location(float(coords[0]), float(coords[1])) else: raise ValueError( f\"Expected input as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01, got {location}\" ) request_route(url, start, end, status_update_delay=30, num_requests=10, force_new_route=False, mesh_id=None, tags=None) Requests a route from polarRouteServer, monitors job status until complete, then retrieves route data. Parameters: url ( str ) \u2013 Base URL to send request to. start ( Location ) \u2013 Start location of route end ( Location ) \u2013 End location of route status_update_delay ( int , default: 30 ) \u2013 Delay in seconds between each status request. Defaults to 10. num_requests ( int , default: 10 ) \u2013 Max number of status requests before giving up. Defaults to 10. force_new_route ( bool , default: False ) \u2013 Force recalculation of an already existing route. Default: False. mesh_id ( int , default: None ) \u2013 Custom mesh ID to use for route calculation. Default: None. tags ( list , default: None ) \u2013 Tags to assign to the route. Default: None. Raises: Exception \u2013 If no status URL is returned. Returns: str ( str ) \u2013 JSON response of route data, or None if request failed. Source code in request_route/request_route.py def request_route( url: str, start: Location, end: Location, status_update_delay: int = 30, num_requests: int = 10, force_new_route: bool = False, mesh_id: int = None, tags: list = None, ) -> str: \"\"\"Requests a route from polarRouteServer, monitors job status until complete, then retrieves route data. Args: url (str): Base URL to send request to. start (Location): Start location of route end (Location): End location of route status_update_delay (int, optional): Delay in seconds between each status request. Defaults to 10. num_requests (int, optional): Max number of status requests before giving up. Defaults to 10. force_new_route (bool, optional): Force recalculation of an already existing route. Default: False. mesh_id (int, optional): Custom mesh ID to use for route calculation. Default: None. tags (list, optional): Tags to assign to the route. Default: None. Raises: Exception: If no status URL is returned. Returns: str: JSON response of route data, or None if request failed. \"\"\" # make route request response_body, status = make_request( \"POST\", url, \"/api/route\", {\"Content-Type\": \"application/json\"}, json.dumps( { \"start_lat\": start.lat, \"start_lon\": start.lon, \"end_lat\": end.lat, \"end_lon\": end.lon, \"start_name\": start.name, \"end_name\": end.name, \"force_new_route\": force_new_route, \"mesh_id\": mesh_id, \"tags\": tags, }, ).encode(\"utf-8\"), ) print(pprint.pprint(response_body)) if not str(status).startswith(\"2\"): return None # if route is returned if response_body.get(\"json\") is not None: return response_body[\"json\"] # if no route returned, request status at status-url status_url = response_body.get(\"status-url\") if status_url is None: print( \"No status URL returned. Route may have failed or been returned immediately.\" ) return None job_id = response_body.get(\"id\") status_request_count = 0 while status_request_count <= num_requests: status_request_count += 1 # make job status request print(f\"Status request #{status_request_count} of {num_requests}\") status_response, status_code = make_request( \"GET\", status_url, None, headers={\"Content-Type\": \"application/json\"}, ) print(f\"Route calculation {status_response.get('status')}.\") print(pprint.pprint(status_response)) if status_response.get(\"status\") == \"PENDING\": print( f\"\\nWaiting for {status_update_delay} seconds before sending status request.\" ) time.sleep(status_update_delay) continue elif status_response.get(\"status\") == \"FAILURE\": return None elif status_response.get(\"status\") == \"SUCCESS\": # Job is complete, now get the actual route data route_url = status_response.get(\"route_url\") if route_url: # Extract route ID from the route_url (e.g., \"/api/route/123\") route_id = status_response.get(\"route_id\") print(f\"Job complete! Fetching route data from route ID: {route_id}\") route_response, route_status = make_request( \"GET\", route_url, None, headers={\"Content-Type\": \"application/json\"}, ) if str(route_status).startswith(\"2\"): return route_response else: print(f\"Failed to fetch route data: {route_status}\") return None else: print(\"Job completed but no route_url provided\") return None print( f'Max number of requests sent. Quitting.\\nTo send more status requests, run: \"curl {url}/api/job/{job_id}\"' ) return None","title":"request_route"},{"location":"autoapi/request_route/request_route/#request_route.request_route.make_request","text":"Sends HTTP request, prints details and returns response. Parameters: type ( str ) \u2013 HTTP request type, e.g. \"GET\" or \"POST\" url ( str ) \u2013 base url to send request to endpoint ( str ) \u2013 endpoint, e.g. \"/api/route/some-id\" headers ( dict ) \u2013 HTTP headers body ( dict , default: None ) \u2013 HTTP request body. Defaults to None. Returns: HTTPResponse \u2013 http.client.HTTPResponse HTTPResponse \u2013 status Source code in request_route/request_route.py def make_request( type: str, url: str, endpoint: str, headers: dict, body: dict = None ) -> http.client.HTTPResponse: \"\"\"Sends HTTP request, prints details and returns response. Args: type (str): HTTP request type, e.g. \"GET\" or \"POST\" url (str): base url to send request to endpoint (str): endpoint, e.g. \"/api/route/some-id\" headers (dict): HTTP headers body (dict, optional): HTTP request body. Defaults to None. Returns: http.client.HTTPResponse status \"\"\" sending_str = f\"Sending {type} request to {url}{endpoint}: \\nHeaders: {headers}\\n\" if body: sending_str += f\"Body: {body}\\n\" print(sending_str) request_url = url + endpoint if endpoint else url req = request.Request(request_url, data=body, headers=headers) unverified_context = ssl._create_unverified_context() try: response = request.urlopen(req, context=unverified_context) except HTTPError as err: print(f\"A HTTPError was thrown: {err.code} {err.reason}\") print( \"One possibility is that there is no mesh available.\" ) # this is a quick and dirty workaround since urllib throws errors on 404, even though this is a valid use of a that error code return None, err.status print(f\"Response: {response.status} {response.reason}\") return json.loads(response.read()), response.status","title":"make_request"},{"location":"autoapi/request_route/request_route/#request_route.request_route.parse_location","text":"Parameters: location ( str ) \u2013 a location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 Returns: Location \u2013 a Location object Source code in request_route/request_route.py def parse_location(location: str) -> Location: \"\"\" Args: location (str): a location either as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01 Returns: a Location object \"\"\" pattern = r\"[+-]?([0-9]*[.])?[0-9]+,[+-]?([0-9]*[.])?[0-9]+\" if location in STANDARD_LOCATIONS.keys(): standard_location = STANDARD_LOCATIONS.get(location) return standard_location elif re.search(pattern, location): coords = re.search(pattern, location).group().split(\",\") return Location(float(coords[0]), float(coords[1])) else: raise ValueError( f\"Expected input as the name of a standard location or latitude,longitude separated by a comma, e.g. -56.7,-65.01, got {location}\" )","title":"parse_location"},{"location":"autoapi/request_route/request_route/#request_route.request_route.request_route","text":"Requests a route from polarRouteServer, monitors job status until complete, then retrieves route data. Parameters: url ( str ) \u2013 Base URL to send request to. start ( Location ) \u2013 Start location of route end ( Location ) \u2013 End location of route status_update_delay ( int , default: 30 ) \u2013 Delay in seconds between each status request. Defaults to 10. num_requests ( int , default: 10 ) \u2013 Max number of status requests before giving up. Defaults to 10. force_new_route ( bool , default: False ) \u2013 Force recalculation of an already existing route. Default: False. mesh_id ( int , default: None ) \u2013 Custom mesh ID to use for route calculation. Default: None. tags ( list , default: None ) \u2013 Tags to assign to the route. Default: None. Raises: Exception \u2013 If no status URL is returned. Returns: str ( str ) \u2013 JSON response of route data, or None if request failed. Source code in request_route/request_route.py def request_route( url: str, start: Location, end: Location, status_update_delay: int = 30, num_requests: int = 10, force_new_route: bool = False, mesh_id: int = None, tags: list = None, ) -> str: \"\"\"Requests a route from polarRouteServer, monitors job status until complete, then retrieves route data. Args: url (str): Base URL to send request to. start (Location): Start location of route end (Location): End location of route status_update_delay (int, optional): Delay in seconds between each status request. Defaults to 10. num_requests (int, optional): Max number of status requests before giving up. Defaults to 10. force_new_route (bool, optional): Force recalculation of an already existing route. Default: False. mesh_id (int, optional): Custom mesh ID to use for route calculation. Default: None. tags (list, optional): Tags to assign to the route. Default: None. Raises: Exception: If no status URL is returned. Returns: str: JSON response of route data, or None if request failed. \"\"\" # make route request response_body, status = make_request( \"POST\", url, \"/api/route\", {\"Content-Type\": \"application/json\"}, json.dumps( { \"start_lat\": start.lat, \"start_lon\": start.lon, \"end_lat\": end.lat, \"end_lon\": end.lon, \"start_name\": start.name, \"end_name\": end.name, \"force_new_route\": force_new_route, \"mesh_id\": mesh_id, \"tags\": tags, }, ).encode(\"utf-8\"), ) print(pprint.pprint(response_body)) if not str(status).startswith(\"2\"): return None # if route is returned if response_body.get(\"json\") is not None: return response_body[\"json\"] # if no route returned, request status at status-url status_url = response_body.get(\"status-url\") if status_url is None: print( \"No status URL returned. Route may have failed or been returned immediately.\" ) return None job_id = response_body.get(\"id\") status_request_count = 0 while status_request_count <= num_requests: status_request_count += 1 # make job status request print(f\"Status request #{status_request_count} of {num_requests}\") status_response, status_code = make_request( \"GET\", status_url, None, headers={\"Content-Type\": \"application/json\"}, ) print(f\"Route calculation {status_response.get('status')}.\") print(pprint.pprint(status_response)) if status_response.get(\"status\") == \"PENDING\": print( f\"\\nWaiting for {status_update_delay} seconds before sending status request.\" ) time.sleep(status_update_delay) continue elif status_response.get(\"status\") == \"FAILURE\": return None elif status_response.get(\"status\") == \"SUCCESS\": # Job is complete, now get the actual route data route_url = status_response.get(\"route_url\") if route_url: # Extract route ID from the route_url (e.g., \"/api/route/123\") route_id = status_response.get(\"route_id\") print(f\"Job complete! Fetching route data from route ID: {route_id}\") route_response, route_status = make_request( \"GET\", route_url, None, headers={\"Content-Type\": \"application/json\"}, ) if str(route_status).startswith(\"2\"): return route_response else: print(f\"Failed to fetch route data: {route_status}\") return None else: print(\"Job completed but no route_url provided\") return None print( f'Max number of requests sent. Quitting.\\nTo send more status requests, run: \"curl {url}/api/job/{job_id}\"' ) return None","title":"request_route"}]}